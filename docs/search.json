[
  {
    "objectID": "Textbook/Stat_Process.html",
    "href": "Textbook/Stat_Process.html",
    "title": "The Statistical Process",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe the five steps of the Statistical Process\nDistinguish between an observational study and an experiment\nDifferentiate between a population and a sample\nDescribe each of the following sampling schemes:\n\nSimple random sampling\nStratified sampling\nSystematic sampling\nCluster sampling\nConvenience sampling\n\nExplain the importance of using random sampling\nDistinguish between a quantitative and a categorical variable"
  },
  {
    "objectID": "Textbook/Stat_Process.html#lesson-outcomes",
    "href": "Textbook/Stat_Process.html#lesson-outcomes",
    "title": "The Statistical Process",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDescribe the five steps of the Statistical Process\nDistinguish between an observational study and an experiment\nDifferentiate between a population and a sample\nDescribe each of the following sampling schemes:\n\nSimple random sampling\nStratified sampling\nSystematic sampling\nCluster sampling\nConvenience sampling\n\nExplain the importance of using random sampling\nDistinguish between a quantitative and a categorical variable"
  },
  {
    "objectID": "Textbook/Stat_Process.html#introduction",
    "href": "Textbook/Stat_Process.html#introduction",
    "title": "The Statistical Process",
    "section": "Introduction",
    "text": "Introduction\nStatistics are used in every aspect of society. Every statistical analysis follows a pattern we will call the Statistical Process. This process will be introduced in this lesson and will be used throughout the course.\n\n\nThe Statistical Process and Daniel’s Experiment\n\n\n\nStained-glass depiction of Daniel’s deliverance from the lions’ den. Found in the old Dominican priory church at Hawkesyard in Staffordshire, England. (Photo credit: Fr Lawrence Lew, O.P. Used by permission.)\n\n\n\nThe Old Testament prophet Daniel planned one of the earliest recorded scientific research studies. We will use his example to illustrate the following five steps of The Statistical Process.\nThe following icons can help you remember these steps. Notice that each icon has a letter and an image to help you remember the five steps of the Statistical Process.\n\n\n\n\n\n\n\n\n\n\n\nThe Statistical Process\n\n\n\n\n\n\nDesign the Study\n\n\n\nCollect the Data\n\n\n\nDescribe the Data\n\n\n\nMake Inference\n\n\n\nTake Action\n\n\n\n\n\n\n\nStep 1: Design the Study\n\nAn important step in scientific inquiry or problem solving can be to state a research question such as:\n\nWill internet advertising increase a company’s revenue?\nDoes expressing gratitude increase a person’s satisfaction with life in general?\nDoes a newly developed vaccine prevent the spread of disease?\n\nResearchers also investigate the background of the situation. What have other people discovered about this situation? How can we find the answer to the research question? What do we need to do? What is the population (or total collection of all individuals) under consideration? What kind of data need to be collected?\nBefore collecting data, researchers make a hypothesis, or an educated guess about the outcome of their research. A hypothesis is a statement such as the following:\n\nUsing internet advertising will increase the company’s sales revenue.\nPeople who express gratitude will be more satisfied with life than those who do not.\nA newly-developed vaccine is effective at preventing tuberculosis.\n\n\n\nDaniel’s Experiment\nAfter taking Israel captive, Babylon’s King Nebuchadnezzar asked his chief officer to bring Israelite children who were well favoured, and skilful in all wisdom, and cunning in knowledge, and understanding science to stand in the king’s palaces (Daniel 1:4). To aid their preparation, Nebuchadnezzar planned to feed them his meat and wine for three years (Daniel 1:5).\nDaniel did not want to defile himself by partaking of the king’s meat and wine. He asked permission to eat pulse[^1] and drink water instead. His supervisor, Melzar, was afraid to displease the king. He thought that after eating pulse and water, the selected Israelites would look worse than their peers, and he would be punished (Daniel 1:8-10).\nWith an understanding of the background of the situation, Daniel proposed an experiment. He said, Prove thy servants, I beseech thee, ten days; and let them give us pulse to eat, and water to drink. Then let our countenances be looked upon before thee, and the countenance of the children that eat of the portion of the king’s meat: and as thou seest, deal with thy servants (Daniel 1:12-13.). In short, Daniel’s implied research question can be stated as: Will those who eat pulse and drink water appear healthier than those who eat the king’s meat and drink his wine? Melzar agreed to the experiment.\n\nAnswer the following question:\n\n\n\nWhat is Daniel’s hypothesis?\n\nShow/Hide Solution\n\nDaniel’s hypothesis is that the Israelite children who eat pulse and drink water will appear healthier in just ten days, compared to those who eat the king’s meat and drink his wine.\n\n\n\n\n\n\nStep 2: Collect Data\n\nWhen designing a study, much attention is given to the process by which data are observed. When examining data, it is also important to understand the data collection procedures. A sample is a subset (a portion) of a population. How is this sample obtained? How are the observations made?\nDaniel’s study design required that data be collected at the end of 10 days. Melzar would compare the appearances of two groups of people: (1) Israelites who ate pulse and drank water versus (2) Israelites who ate the king’s meat and drank his wine.\n\n\n\nStep 3: Describe the Data\n\nWhen we describe data, we use any tools appropriate to the situation. This can include creating graphs or calculating statistics to help understand or visualize the data.\nFor Daniel’s experiment, the data are described in Daniel 1:15: And at the end of ten days [the] countenances [of those who ate pulse] appeared fairer and fatter in flesh than all the children which did eat the portion of the king’s meat.\n\n\n\nStep 4: Make Inferences\n\nInference is the process of using the information contained in a sample from a population to make a general statement (i.e. to infer something) about the entire population. Later in the course we will learn techniques that make this type of analysis possible.\nMelzar made an inference. Based on the results of the sample, he determined that (in general) those who eat pulse and drink water will be healthier than those who eat the king’s meat and drink his wine Daniel 1:15-16.\n\n\n\nStep 5: Take Action\n\nThe goal of a statistical analysis is to determine which action to take in a particular situation. Actions can include many things: launching an internet ad campaign (or not), expressing gratitude (or not), getting vaccinated (or not), etc.\nMelzar took action as described in Daniel 1:16: Thus Melzar took away the portion of their meat, and the wine that they should drink; and gave [all the Israelite children] pulse.\nWas the experiment a success?\n“Now at the end of the days that the king had said he should bring them in… the king communed with them; and among them all was found none like Daniel, Hananiah, Mishael, and Azariah And in all matters of wisdom and understanding, that the king enquired of them, he found them ten times better than all the magicians and astrologers that were in all his realm” Daniel 1:18-20.\n\n\n\nSummary of the Statistical Process\n\nDaniel’s experience can also help you learn the Statistical Process. Look at the first letter of each of the steps in the Statistical Process. You can use the phrase “Daniel Can Discern More Truth” to help you to help you remember the five steps in the Statistical Process.\n\nThe Statistical Process\n\n\n\n\n \nPneumonic\nActual Process Step\n\n\n\n\nStep 1:\nDaniel\nDesign the study\n\n\nStep 2:\nCan\nCollect data\n\n\nStep 3:\nDiscern\nDescribe the data\n\n\nStep 4:\nMore\nMake inferences\n\n\nStep 5:\nTruth\nTake action\n\n\n\n\nThe Statistical Process will be used throughout the course. Take time to memorize the five steps.\n\n\nThe study designed by the Old Testament prophet Daniel provides an ancient example of a designed experiment. Daniel’s experiment included two groups of people: those who had the experimental treatment eating pulse and drinking water (called the treatment group) and those who ate the standard food the king’s meat (called the control group.) The treatment group receives the experimental procedure. The control group is used for comparison.\n\nAnswer the following question:\n\n\n\nWhy was it important that Daniel’s experiment included a control group?\n\nShow/Hide Solution\n\nIf there was no control group, then there would be no way to compare the effect of the diets (the treatments). Having a control group allows a researcher to see the effect of not taking any action. For Daniel, the control group (who ate the king’s meat and drank his wine) provided a basis for comparing the effect of the new treatment (i.e. eating pulse and drinking water.)"
  },
  {
    "objectID": "Textbook/Stat_Process.html#design-of-studies",
    "href": "Textbook/Stat_Process.html#design-of-studies",
    "title": "The Statistical Process",
    "section": "Design of Studies",
    "text": "Design of Studies\nMost research projects can be classified into one of two basic categories: observational studies or designed experiments. In an experiment, researchers control (to some extent) the conditions under which measurements are made. In an observational study, researchers simply observe what happens, without controlling the conditions under which measurements are made. Both types of study follow the five steps of the Statistical Process.\n\n\nDesigned Experiments\nIn a designed experiment, researchers manipulate the conditions that the participants experience. They often do this by randomly assigning subjects to one of two groups, a “treatment” group (sometimes called the experimental group) and a “control” group (though this could be second treatment group instead of a control group). The experiment is typically conducted by applying some kind of treatment to the subjects in the treatment group and observing the effect of the treatment. Those in the control group do not receive the treatment and are also observed. In this way researchers can determine the effects of the treatment by comparing the treatment group results to the control group results. The following example illustrates the use of these two groups.\nJonas Salk’s First Polio Vaccine Trial\nBeginning around 1916 and through the 1950s, a mysterious plague attacked infants and children. Symptoms included excruciating muscle pain and a stiff neck. This illness, which became known as poliomyelitis or simply “polio,” left children disfigured, paralyzed, and sometimes even dead.\nWhile working as a researcher at the University of Pittsburgh School of Medicine, Dr. Jonas E. Salk developed a vaccine that might help prevent the spread of this disease. He conducted what has become one of the most famous designed experiments in history.\nThis short video below provides a compelling summary of the famous Jonas Salk vaccine experiment. As you watch, notice each of the 5 steps of a statistical study in this study.  \nAs explained in the video, in the first Salk trial almost 1.1 million children participated in the study. Even though the sample size was large, flaws in the study design rendered the results useless.\nUndaunted, Dr. Salk fixed the problems with the design and enrolled hundreds of thousands of additional children for the second phase of his study. In all, over 1.8 million infants and children participated in this experiment, making it the largest drug trial to date.\n\nStep 1: Design the study.\nThe participants in a study are commonly called subjects. Sometimes subjects are called experimental units or simply units. In the Salk trials, the children who participated were the subjects.\nSubjects (the children) were randomly assigned to one of two groups. The first group was given the experimental vaccine, the treatment. The treatment is the new or experimental condition that is imposed on the subjects. The subjects who receive the treatment make up the treatment group.\nThe second group was given a control or placebo. In this study, the control was an injection that looked just like the vaccine, but contained a harmless saline solution. The control group or placebo group is made up of the subjects assigned to receive the control.\nThis study was double blind. Neither the children’s parents nor their doctors knew whether a particular child received the treatment or the control. Both parties were blinded to this information.\nBecause the children were assigned to the groups randomly, the two groups should be similar. If the vaccine is not effective, the number of future cases of polio should be about the same in each group. However, if Salk’s vaccine helped to prevent the spread of polio, then fewer cases should occur in the vaccinated group.\n\nAnswer the following questions:\n\n\n\nSome children can be identified as having a higher risk of developing polio. Would it have been better if they were assigned to the treatment group so they could get the vaccine?\n\nShow/Hide Solution\n\n\nNo. The two groups need to be as similar as possible. Specifically, the people in the treatment group need to have the same potential (on average) of contracting polio as the people in the control group. If we put the people who are at a higher risk of developing polio in the treatment group, we run the risk of having more people in the treatment group getting polio simply because they are more likely to get it, whether they are vaccinated or not. Likewise, we might have fewer people in the control group getting polio just because they are less likely to get it, whether they are vaccinated or not.\nThese two effects would create a bias against the vaccine, by making the vaccine look like it doesn’t work, or doesn’t work as well as it does. It might also make it appear that people who aren’t vaccinated stay healthy and the vaccine is not needed. There is even a chance that people will conclude that the vaccine actually gives people polio.\nRandomly assigning subjects to the two groups tends to yield groups with similar characteristics—in this example, similar potential for contracting polio. Randomly assigning subjects to groups therefore defends us against problems like those mentioned in the previous paragraph.\n\n\n\n\nWhy is it important for the subject and those who assess the health of the subject to be unaware of whether or not that child received the vaccine?\n\nShow/Hide Solution\n\n\nSubjects: Suppose a subject in the study thinks they’re being treated. It has been documented that subjects with such knowledge tend to show improvement whether they are receiving the treatment or not. To see why, consider how you might feel and act if you were told you had been vaccinated. You might have a more hopeful outlook, leading to healthier living habits such as better hygiene and nutrition. Such changes would tend to reduce your chance of contracting polio whether you’ve received the vaccine or not. This might make the vaccine look like it works better than it does. It also might make the vaccine look like it works, even if it doesn’t.\nNow suppose subjects in the control group know they are not being treated. This can also change the way they feel and act, in ways that can make them more likely to contract polio than they would be if they weren’t in the study. This could make it look like the incidence of polio among unvaccinated persons is higher than it is, again making the vaccine look like it works better than it does.\nTo reduce bias caused by such errors, subjects should not know to which group they are assigned.\nResearchers: Suppose a researcher assessing the health of a subject is told that the subject is in the control group. It has been documented that in such a case, the researcher is more likely to record that the subject has symptoms even if the subject is not actually in the control group. This makes it look like unvaccinated persons are more likely to get polio than they really are, which makes it look like the vaccine works better than it does.\nThere are other effects of knowing to which group the subject belongs, such as doctors treating or advising the patient differently than they would without such knowledge. Such differences can make it harder to tell whether the vaccine works, and how well.\nTo reduce bias caused by such effects, those assessing the health of the subjects should not be told to which group the subject belongs.\n\n\n \n\n\n\nStep 2: Collect data.\nThe researchers followed up with each child to determine if they contracted polio. They recorded the number of children in each group that developed polio during the study period. Not all of Salk’s experiments were double-blind. Here is a summary of the results from the regions where a double-blind study was conducted (Francis et al., 1955; Brownlee, 1955):\n\n\nChildren Who Developed Polio\n\n\n\n\n\n\n\nYes\n\n\n\n\nNo\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\nTreatment Group\n\n\n\n\n57\n\n\n\n\n200,688\n\n\n\n\n200,745\n\n\n\n\n\n\nPlacebo Group\n\n\n\n\n142\n\n\n\n\n201,087\n\n\n\n\n201,229\n\n\n\n\n\n\nStep 3: Describe the data.\nOne way to summarize the data is to compute the proportion of children in each group that developed polio. The proportion of children in the treatment group that developed polio during the study period is:\n\\[ \\frac{57}{200745} = 0.000~283~9 \\]\n\nAnswer the following questions:\n\n\n\nCalculate the proportion of children in the placebo group that developed polio during the study period.\n\nShow/Hide Solution\n\n\n\\[ \\displaystyle{\\frac{142}{201229} = 0.000~705~7} \\]\n\n\n\n\nCompare the two proportions. What do you observe?\n\nShow/Hide Solution\n\n\nThe proportion of children in the placebo group that develop polio during the study period was more than double the proportion of children in the treatment group that developed polio during the study period. That suggests that the treatment is effective in reducing the proportion of children that will develop polio.\n\n\n\n\n\n\nStep 4: Make inferences\nCareful statistical analysis of the records suggested that this difference was so great that it was attributable to the vaccine and not to chance. Assuming that the vaccine had no effect, the probability that the difference in the proportions between the two groups would be at least as extreme as the difference Dr. Salk observed was very low: 0.00000000093. Because this probability is so small, it is highly unlikely that these results are due to chance.\n\n\nStep 5: Take action\nOnce it was clear that the vaccine was effective, children who were unvaccinated or had received the placebo were given Salk’s vaccine. Since 1954, there has been a marked decrease in the number of polio cases worldwide (Offit, 2005). Public health researchers are striving to eradicate this disease entirely.\n\n\n\nObservational Studies\nIn an observational study researchers observe the responses of the individuals, without controlling the conditions experienced by the individuals. Therefore, they do not assign the participants to treatment or control groups.\nObservational studies commonly occur in business settings. One example is a financial audit. The purpose of a financial audit is to assess the accuracy of a company’s financial business practices. ImmunAvance Ltd., a non-government health care organization, hired the Accounting Office at Global Optimization Unlimited to perform an independent audit of their financial practices. ImmunAvance provides inoculation and other preventative health care services in rural African communities.\n\n\n\nStep 1: Design the study\nThe volume of financial transactions conducted by ImmunAvance makes it impossible to conduct a census or an examination of the entire collection of ImmunAvance’s financial documents. Instead, you will collect a manageable group of items (called the sample) from the entire collection of financial documents (called the population.) A sample is a subset or a portion of a population. The information gained from the sample is used to make an inference (or generalization) about the population.\nAuditors typically cannot consider every item in a population, because there are too many. When it is not possible to conduct a census, auditors face sampling risk. Sampling risk is the risk affiliated with not auditing every item in the population. It is the risk that the sample may not adequately reflect the population. The only way to eliminate sampling risk is to conduct a census, which is usually not practical. Auditors can reduce sampling risk by obtaining a sample randomly. This is called random selection. Another way to reduce sampling risk is to increase the sample size, the number of items sampled.\n\n\n\n\nSampling Methods\nStep 2: Collect data\nThere are several procedures that can be used to select a random sample from a population, including: simple random sampling (SRS), stratified sampling, systematic sampling, cluster sampling, , and convenience sampling (or, haphazard sampling). These are examples of sampling methods.\n\nRandom Sampling Methods\nA simple random sample (SRS) is the best method for obtaining a sample from a population. This method allows each possible sample of a certain size an equal chance at being selected as the chosen sample. A difficulty of this method is that a list of all of the items in the population must be accessible before the sample is taken. Often, we obtain a SRS by allowing a computer to randomly select a certain number of items from the full list of the population. It is akin to the idea of putting all of the names into a hat, shaking them up, and randomly drawing out a few.\n\nFor example, suppose there are 18,000 students in the population of a certain university. School officials can use a computer to randomly choose values between 1 and 18,000 to identify which students are to be selected to complete a survey. In Excel, the command to obtain a random number between 1 and 18,000 is =RANDBETWEEN(1,18000). A simple random sample can be obtained any time there is a complete list of the items to be sampled and they are all accessible. All the statistical procedures in this course assume that simple random sampling has been used. But in practice, the SRS is often difficult (or impossible) to implement.\n\nA stratified sample is when the items to be sampled are organized in groups of homogeneous (similar) items called strata, then a simple random sample is drawn from each of these strata. Stratified sampling works well when the items are similar within each stratum and tend to differ from one stratum to another. We often use stratified sampling in order to obtain a sample in such a way that we can make comparisons between each of the groups (or strata).\n\nFor example, in obtaining a sample of students from a university, school officials could define the strata as: (1) freshman, (2) sophomores, (3) juniors, and (4) seniors. A simple random sample could then be obtained from each of these strata. This would ensure that each class rank of students was represented in the sample. It would also allow the school officials to see how freshman, sophomore, junior, and senior level students compared in their answers to a survey.\n\nA systematic sample is where every \\(k^{\\text{th}}\\) item in the population is selected to be part of the sample, beginning at a random starting point. Systematic sampling works well when the items are in a random, but sequential ordering. If the items are not arranged randomly, a systematic sample can miss important parts of the population.\n\nFor example, consider a fast food company where every 10th customer is given the opportunity to compete a satisfaction survey in exchange for a small discount coupon towards their next purchase. An airport security line also often implements a procedure where every 100th (or so) person is selected for a more “in depth” security examination. Similarly, factories that use assembly lines will pull say every 500th item from the assembly line to perform a quality control check on the item.\n\nA cluster sample (sometimes called a block sample) consists of taking all items in one or more randomly selected clusters, or blocks. When the variation from one block to another is relatively low, compared to the variation within the block, cluster sampling is a reasonable way to get a sample.\n\nFor example, ecologists could draw grids on a map of a forest to create small sampling regions, or sampling clusters. Then, by randomly selecting one or two of these clusters from the map, the ecologists could go to the areas marked on the map and document information on the health of every tree they find in those clusters. This is a practical way to get a sample in this case because the ecologists only have to go to a few areas of the forest, but are still able to obtain a random sample of all of the trees in the forest. It is also worth noting that the ecologists would not be interesting in comparing the health of the trees from the selected clusters to each other like they would in a stratified sample. Instead, they are just looking for a feasible way to obtain a single random sample of all of the trees in the forest, but want to keep their traveling time to a minimum while collecting their sample. In contrast, to obtain a simple random sample of trees from the same forest, the ecologists would first have to go out and number every tree in the entire forest. Then they would need to use a computer to randomly pick which trees to collect data on. Finally, they would then have to go back to the forest and collect data on the selected trees from across the entire forest. Such an approach just isn’t feasible in practice, so we are willing to settle instead for the cluster sample.\n\nA convenience sample involves selecting items that are relatively easy to obtain and does not use random selection to choose the sample. This method of sampling can be assumed to always bring bias into the sample.\n\nAs an example of a convenience sample, an auditor could haphazardly select items from a filing cabinet. This is frequently done when a quick and simple sample is needed, but may not yield a sample that represents the population well. When possible, convenience samples should be avoided.\n\n\n\n\n\nTypes of Data\nWhenever we collect data, we record information about the things we are studying. There are two basic types of data that can be recorded: quantitative measurements and categorical labels. We will call these types of data simply “quantitative” or “categorical” variables. We use the word “variable” to denote the idea that the quantitative measurements or categorical labels can vary from person to person, or item to item, in our study.\nQuantitative variables provide measurement information on each individual (or item) in our study. They represent things that are numeric in nature; things that are measured. They often include units of measurement along with the quantitative value of the measurement. For example, the heights of children measured in inches (or centimeters), or their weight measured in pounds (or kilograms). For a quantitative variable, it makes sense to apply arithmetic operations to the data (such as adding values together, computing the average of the values, or comparing two values). If one child weighs 30 pounds (13.61 kg) and a second child weights 60 pounds (27.22) then the second child is twice as heavy as the first.\nCategorical variables allow us to place each individual (or item) into to a specific category. Categorical variables are labels, and it does not make sense to do arithmetic with them. For example the gender of a newborn child, the ethnicity of an individual, a person’s job title, the brand of phone they own, or the area code of a telephone number, etc are all categorical variables. Notice that although a telephone number consists of numbers, it is not a quantitative measurement. It does not make sense to double someone’s phone number, to average phone numbers together, or to say one phone number is half the size of another. But the area code of the phone number gives information about the region where the phone number was first initiated, which is categorical information.\nIn Unit 3 of this course we will learn more about categorical variables and proportions. Units 1 and 2 of this course focus on studying quantitative variables.\nReturning to the sample accounts receivable record, we find this data to have information on both types of variables.\n\nAnswer the following question:\n\n\n\nFor each of the following variables taken from this accounts receivable record, indicate whether the variable is quantitative or categorical.\n\n\n\nTerms\n\nShow/Hide Solution\n\n\nThe variable “Terms” is categorical. It classifies the invoice by the terms of payment for that invoice.\n\n\n\n\nAccount number\n\nShow/Hide Solution\n\n\nThe variable “Account number” is categorical. Even though the account number is given a number, it is actually functioning as a label. It is not something that is counted or measured. It does not make sense to do arithmetic operations (like adding 1 or multiplying by 2) to the account number.\n\n\n\n\nInvoice amount\n\nShow/Hide Solution\n\n\nThe variable “Invoice amount” is quantitative. It makes sense to do arithmetic operations to this value. For example, the amount of Invoice 5745 (which is $990.00) is somewhat more than twice as much as that of Invoice 2378 (which is $478.00).\n\n\n \n\n\n\nStep 3: Describe the data\nAfter auditors collect a sample and compile the data, they review the evidence. Auditors may use graphs or compute numbers (such as the average) to summarize the evidence they found."
  },
  {
    "objectID": "Textbook/Stat_Process.html#making-inferences-hypothesis-testing",
    "href": "Textbook/Stat_Process.html#making-inferences-hypothesis-testing",
    "title": "The Statistical Process",
    "section": "Making Inferences: Hypothesis Testing",
    "text": "Making Inferences: Hypothesis Testing\nStep 4: Make inferences\nAuditors use the information drawn from the sample to form an opinion about the population. Whenever sample data is used to infer a characteristic of a population, it is called making an inference. Inferential statistics represents a collection of methods that can be used to make inference about a population. Based on the documents reviewed, the auditors assess if the company is conducting its business in a proper manner.\nWhen conducting an audit, the implicit assumption is that transactions have been posted properly. As auditors sample the company’s records, they are looking to see if everything is consistent with the original assumption that all transactions have been posted properly. It would only be in the case of discovering suspicious activity or evidence of fraudulent reporting that the auditors would change their belief about the company and accuse the company ImmunAvance of falsely reporting on their financial statements.\n\n“Piled Higher and Deeper” by Jorge Cham  \n\nThere is a formal procedure for determining when enough evidence has been found to make accusations of fraud. Later this semester, after we establish some foundational principles of statistics, we will study these statistical methods in depth. Of course, these methods can be used for much more than just determining if a company has reported their financial statements fraudulently. So we will look at many different ways these statistical procedures can be applied to research and industry.\nFor ImmunAvance’s audit, based on the samples of financial statements that had been selected, while there were a few errors in the documents, there was not evidence dramatic enough to claim that the company had been fraudulent. So the company passed their audit.\n\nStep 5: Take Action\nThe auditors prepare a report in which they give their opinion on the status of the company’s current operations.\nSince there was not enough evidence to suggest that ImmunAvance’s financial statements were fraudulent, the auditor’s conclusion is that no adjustment is necessary. The few observed discrepancies were apparently just the result of random chance errors, not the deliberate falsefying of information."
  },
  {
    "objectID": "Textbook/Stat_Process.html#summary",
    "href": "Textbook/Stat_Process.html#summary",
    "title": "The Statistical Process",
    "section": "Summary",
    "text": "Summary\n\nRemember…\n\n\n\nThe Statistical Process has five steps: Design the study, Collect the data, Describe the data, Make inference, Take action. These can be remembered by the pneumonic “Daniel Can Discern More Truth.”\nIn a designed experiment, researchers control the conditions of the study, typically with a treatment group and a control group, and then observe how the treatments impact the subjects. In a purely observational study, researchers don’t control the conditions but only observe what happens.\nThe population is the entire group of all possible subjects that could be included in the study. The sample is the subset of the population that is actually selected to participate in the study. Statistics use information from the sample to make claims about what is true about the entire population.\nThere are many sampling methods used to obtain a sample from a population. The best methods use some sort of randomness (like pulling names out of a hat, rolling dice, flipping coins, or using a computer generated list of random numbers) to avoid bias.\n\n\nA simple random sample (SRS) is a random sample taken from the full list of the population. This is the least biased (best) sampling method, but can only be implemented when a full list of the population is accessible.\nA stratified sample divides the population into similar groups and then takes an SRS from each group. The main reason to use this sampling method is when a study wants to compare and contrast certain groups within the population, say to compare freshman, sophomores, juniors, and seniors at a university.\nA systematic sample samples every kth item in the population, beginning at a random starting point. This is best applied when subjects are lined up in some way, like at a fast food restaurant, an airport security line, or an assembly line in a factory.\nA cluster sample consists of taking all items in one or more randomly selected clusters, or blocks. For example, ecologists could draw grids on a map of a forest to create small sampling regions and then sample all trees they find in a few randomly selected regions. Note that this differs from a stratified sample in that only a few sub-groups (clusters) are selected and that all subjects within the selected clusters are included in the study.\nA convenience sample involves selecting items that are relatively easy to obtain and does not use random selection to choose the sample. This method of sampling can be assumed to always bring bias into the sample.\n\n\nThe best way to avoid bias when trying to make conclusions about a population from a single sample of that population is to use a random sampling method to obtain the sample.\nQuantitative variables represent things that are numeric in nature, such as the value of a car or the number of students in a classroom. Categorical variables represent non-numerical data that can only be considered as labels, such as colors or brands of shoes."
  },
  {
    "objectID": "Textbook/Stat_Process.html#references",
    "href": "Textbook/Stat_Process.html#references",
    "title": "The Statistical Process",
    "section": "References",
    "text": "References\nBible Dictionary, “Pulse” at http://churchofjesuschrist.org/scriptures/bd/pulse.\nBrownlee, K. A. (1955). Statistics of the 1954 polio vaccine trials. Journal of the American Statistical Association, 50(272), pp. 1005-1013.\nFrancis, T., et. al. (1955). An evaluation of the 1954 poliomyletis vaccine trials. American Journal of Public Health and the Nation’s Health, 45(5)\nOffit, P. A. (2005). Why are pharmaceutical companies gradually abandoning vaccines? Health Affairs, 24(3), 622-630. doi:10.1377/hlthaff.24.3.622"
  },
  {
    "objectID": "Textbook/Shape_and_Center.html",
    "href": "Textbook/Shape_and_Center.html",
    "title": "Describing Quantitative Data (Shape & Center)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nCreate a histogram from data\nInterpret data presented in a histogram\nIdentify left-skewed, right-skewed, and symmetric distributions from histograms\nCalculate the mean, median, and mode for quantitative data using software\nCompare the centers of distributions using graphical and numerical summaries\nDescribe the effects that skewness or outliers have on the relationship between the mean and median\nDistinguish between a parameter and a statistic"
  },
  {
    "objectID": "Textbook/Shape_and_Center.html#lesson-outcomes",
    "href": "Textbook/Shape_and_Center.html#lesson-outcomes",
    "title": "Describing Quantitative Data (Shape & Center)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nCreate a histogram from data\nInterpret data presented in a histogram\nIdentify left-skewed, right-skewed, and symmetric distributions from histograms\nCalculate the mean, median, and mode for quantitative data using software\nCompare the centers of distributions using graphical and numerical summaries\nDescribe the effects that skewness or outliers have on the relationship between the mean and median\nDistinguish between a parameter and a statistic"
  },
  {
    "objectID": "Textbook/Shape_and_Center.html#review-of-the-five-steps-of-the-statistical-process",
    "href": "Textbook/Shape_and_Center.html#review-of-the-five-steps-of-the-statistical-process",
    "title": "Describing Quantitative Data (Shape & Center)",
    "section": "Review of the Five Steps of the Statistical Process",
    "text": "Review of the Five Steps of the Statistical Process\nWe will use the five steps in the Statistical Process throughout the course. Recall the five steps (and the mnemonic “Daniel Can Discern More Truth) before you begin this lesson.\n\n\n\n\n\nStep 1:\n\n\n\n\nDaniel\n\n\n\n\nDesign the study\n\n\n\n\n\n\n\n\nStep 2:\n\n\n\n\nCan\n\n\n\n\nCollect data\n\n\n\n\n\n\nStep 3:\n\n\n\n\nDiscern\n\n\n\n\nDescribe the data\n\n\n\n\n\n\nStep 4:\n\n\n\n\nMore\n\n\n\n\nMake inferences\n\n\n\n\n\n\nStep 5:\n\n\n\n\nTruth\n\n\n\n\nTake action"
  },
  {
    "objectID": "Textbook/Shape_and_Center.html#shape-of-a-distribution",
    "href": "Textbook/Shape_and_Center.html#shape-of-a-distribution",
    "title": "Describing Quantitative Data (Shape & Center)",
    "section": "Shape of a Distribution",
    "text": "Shape of a Distribution\nCost to Treat Tuberculosis in India\n\n  Step 1: Design the study.\nTuberculosis (TB) is the deadliest bacterial disease in the world. In 2009, nine million new cases of tuberculosis were diagnosed, leading to almost 2 million deaths worldwide. Currently, the principal vaccine used to prevent tuberculosis is Bacille Calmette Guerin (BCG). Unfortunately, BCG is only moderately effective at preventing tuberculosis. Historically, India has had a high number of tuberculosis cases. The Indian Government wants to reduce the prevalence of this disease.\nIn this activity, you will compare the average costs of treating a person who contracts tuberculosis to the costs of preventing a case of tuberculosis in India.\n  Step 2: Collect data.\nHealth Care records of tuberculosis patients in India were surveyed to estimate the cost to treat patients with tuberculosis. The following data are representative of the total costs (in US dollars) incurred by society in the treatment of 10 randomly selected tuberculosis patients in India.\n\n15,100     19,000     4,800     6,500     14,900     600     23,500     11,500     12,900     32,200\n\nThese costs include health care treatment, time missed from work, and in some cases utility lost due to death.\n  Step 3: Describe the data.\n\nVisualizing Quantitative Data: Histograms\nThe following data are representative of the total costs (in US dollars) incurred by society in the treatment of 10 randomly selected tuberculosis patients in India.\n\n15,100     19,000     4,800     6,500     14,900     600     23,500     11,500     12,900     32,200\n\nTo help us visualize these data, we will create a graph called a histogram. To make a histogram, we will divide the number line from 0 to 35,000 in seven equal parts. We will then count the number of data points in each of these intervals:\n\n\n\n\n\n\nInterval\n\n\n\n\nNumber of Observations\n\n\n\n\n\n\n\n\nAt least 0 and less than 5,000\n\n\n\n\n2\n\n\n\n\n\n\nAt least 5,000 and less than 10,000\n\n\n\n\n1\n\n\n\n\n\n\nAt least 10,000 and less than 15,000\n\n\n\n\n3\n\n\n\n\n\n\nAt least 15,000 and less than 20,000\n\n\n\n\n2\n\n\n\n\n\n\nAt least 20,000 and less than 25,000\n\n\n\n\n1\n\n\n\n\n\n\nAt least 25,000 and less than 30,000\n\n\n\n\n0\n\n\n\n\n\n\nAt least 30,000 and less than 35,000\n\n\n\n\n1\n\n\n\n\n\n\nFor each of these intervals, called bins, we draw a bar on the histogram. The width of the bars is determined by the width of the bin (5000 in this example). The height of the bars is equal to the number of observations that fall in each bin. As we look at the histogram shown below, we see bars ranging from $0 to $35,000. We also see higher bars in the middle between $10,000 to $20,000 show that these values are more commonly occurring than the other values. If we computed the average of the values contained in our histogram, we would compute the number \\[\n  \\frac{15,100 + 19,000 + 4,800 + 6,500 + 14,900 + 600 + 23,500 + 11,500 + 12,900 + 32,200}{10} = 14,100\n\\] showing that the center of the histogram (or average) is at $14,100.\n\nThis is a histogram created in R: \n\n\n\nTo create this histogram in R, you can copy and paste the following code into R:\n\n# Create a dataset with the costs from 10 randomly selected patients:\ndata &lt;- c(15100, 19000, 4800, 6500, 14900, 600, 23500, 11500,12900, 32200)\n\n# Create a histogram. We add x-axis labels using `xlab = \"\"` and a title `main = \"\"`\nhist(c(15100, 19000, 4800, 6500, 14900, 600, 23500, 11500,12900, 32200), xlab=\"Treatment Costs\", main = \"Tuberculosis Costs in India\")\n\n\n\n\n\n\n\n\n\n\nMaking Inference About the Population\nAfter summarizing the data from our sample of the populations both numerically and graphically, we can use this information to make inference about the full population. \n  Step 4: Make inferences.\nIn the past, the total average cost to society to treat a case of tuberculosis in India was known to be $13,800. As shown in our Step 3 calculations, the 10 randomly selected patients showed an average cost that was higher than the historic value at $14,100. This might make us believe that the actual total average cost to society is also $14,100. However, in depth statistical calculations (that you will be taught how to do later this semestr) show that there is a 46% chance that our sample had an average of $14,100 just by random chance. This isn’t too hard to believe since we only had a sample size of 10 people, and $14,100 is only $300 above $13,800, so it turns out to be fairly likely (46% chance) that because of random chance our sample had an average that was a little higher than the actual value from the population. So we will conclude that the total average cost to society is still essentially the same as it has been in the past.\n\n  Step 5: Take action.\nAfter making inferences, you take action. The motivation for conducting a study like this is usually to see if there is inflation in the costs.\n\nAnswer the following question:\n\n\n\nGiven our conclusion in Step 4 (that the results of our random sample being at an average $14,100 had a 46% probability of just being caused by random chance) do you think the Government of India needs to take any special action to stop the increase in the cost to treat tuberculosis?\n\n\n\nShow/Hide Solution\n\n\nAnswers may vary. – However, we could not say that the true mean cost has really changed from $13,800. So, there is not enough evidence of inflation. There is no need for the Government of India to take action.\n\n\n\n\nOne benefit of using a histogram is that it allows you to visualize the distribution of the data. A histogram illustrates the overall shape of the distribution of the data. The height of the bars show how many observations fall in that range.\n\nAnswer the following question:\n\n\n\nWhich bin of the histogram of tuberculosis costs contained the most data points?\n\n\n\nShow/Hide Solution\n\n\nThe bin going from $10,000 to $15,000 contained 3 observations ($11,500, $12,900, and $14,900), which was the most of any of the bins in the histogram. This can be seen visually in the histogram by looking at the height of each bar and the starting and stopping points of the bar along the x-axis of the graph.\n\n\n\n\nWe will describe the shape of the distribution of a data set using the following basic categories: symmetric, bell-shaped, skewed right, and skewed left. Additionally, we can label the shape of a distribution as uniform, unimodal, bimodal, or multimodal.\nA distribution is symmetric if both the left and right side of the distribution appear to be roughly a mirror image of each other. A special symmetric distribution is a bell-shaped distribution. When data follow a bell-shaped distribution, the histogram looks like a bell. Bell-shaped distributions play an important role in Statistics and will play a role in most of the future lessons.\nA distribution is right-skewed if a histogram of the distribution shows a long right tail. This can occur if there are some very large outliers on the right-hand side of the distribution. A distribution is left-skewed if a histogram shows that it has a long tail to the left.\n\n\n\nRight-skewed\n\n\nSymmetric & Bell-shaped\n\n\nLeft-skewed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean: $10.45\nMedian: $9.04\nMean is to the right of the median.\n\n\nMean: 71.1 inches\nMedian: 71 inches\nMean and median are roughly equal.\n\n\nMean: 3.42\nMedian: 3.45\nMean is to the left of the median.\n\n\n\n\nIf a distribution has only one peak, it is said to be unimodal. The three distributions illustrated above are all unimodal distributions. Some people might argue that there are several peaks in the GPA data, so it should not be considered unimodal. Even though there are jagged bumps in the histogram, it is important to visualize the overall shape in the data. When interpreting a histogram, it can be helpful to blur your eyes and imagine the overall shape after smoothing out the bumps. If the overall trend indicates that there is more than one bump, then we do not consider the distribution to be unimodal. We will usually only work with unimodal data sets in this course.\nSome distributions have no distinct peak, others have more than one peak. When there is no distinct peak, and the histogram shows a relatively flat shape, we might say the data follow a uniform distribution. If there are two distinct peaks, a distribution is called bimodal. If there are more than two peaks, we refer to the distribution as multimodal."
  },
  {
    "objectID": "Textbook/Shape_and_Center.html#center-of-a-distribution",
    "href": "Textbook/Shape_and_Center.html#center-of-a-distribution",
    "title": "Describing Quantitative Data (Shape & Center)",
    "section": "Center of a Distribution",
    "text": "Center of a Distribution\n\nStep 3: Describe the data.\nSometimes people talk about the “typical” BYU-Idaho student or the average waiting time for a bus. But what does it mean for something or someone to be “average?” How can we quantify what it means to be typical or average? In the example below, we will explore one way to define what “average” means.\nWhen we talk about the “typical” or “average” value, we are essentially describing the center of a population. If we want to estimate the “average” costs to treat a tuberculosis patient, there are several ways we can do it.\n\n\nMeasuring the Center of a Distribution\n\nMean\nThe sample mean or sample arithmetic mean is the most common tool to estimate the center of a distribution. It is referred to simply as the mean. It is computed by adding up the observed data and dividing by the number of observations in the data set.\nIn Statistics, important ideas are given a name. Very important ideas are given a symbol. The sample mean has both a name (mean) and a symbol (\\(\\bar x\\), called “x-bar”).\n\\[\n  \\bar{x} \\text{ is used to denote the sample mean}\n\\]\nYou may have heard people refer to the sample mean as the average. Technically, the word average refers to any number that is used to estimate the center of a distribution. The mean, median and mode are all examples of “averages.” To avoid confusion, it is best to use the words mean, median, and mode instead of the word average, so that it is clear which “average” your are referencing.\n\nAnswer the following question:\n\n\n\nPractice finding the mean, \\(\\bar x\\), for the tuberculosis treatment costs of the 10 patients in India by simplifying the following: \\[\\bar x=\\frac{15100 + 19000 + 4800 + 6500 + 14900 + 600 + 23500 + 11500 + 12900 + 32200}{10}=\\]\n\n\n\nShow/Hide Solution\n\n\nThe mean cost to treat the 10 TB patients in India is: \\(\\bar x = \\$14,100\\). To see how to calculate the mean in Excel, see the “Excel Instructions” below.\n\n\n\n\n\n\nMedian\nThe median is the middle value in a sorted data set. Half of the observations in the data set are below the median and half are above the median. To find the median, you:\n\nSort the values from smallest to largest\n\nDo one of the following:\n\nIf there are an odd number of values, the median is the middle value in the sorted list.\nIf there are an even number of values, the median is the mean of the two middle values in the sorted list.\n\n\n\n\nAnswer the following questions:\n\n\n\nPractice finding the median of the tuberculosis treatment costs for the 10 patients in India. First, sort the data from smallest to largest.\n\n\n\nShow/Hide Solution\n\n\n600\n4800\n6500\n11500\n12900\n14900\n15100\n19000\n23500\n32200\n\n\n\n\nSince there are an even number of observations (n=10), the median is computed as the mean of the middle two values. Use your answer to the previous question to find the median of the data. What is the median?\n\n\n\nShow/Hide Solution\n\n\n600\n4800\n6500\n11500\n12900\n14900\n15100\n19000\n23500\n32200\n\nThe middle two numbers are 12900 and 14900. The mean of these two numbers is:\n\n\\(\\text{Median } = \\frac{12900 + 14900}{2} = 13900\\)\n\nThe median cost to treat the ten TB patients in India is $13,900.\n\n\n\n\n\nMode\nThe most frequently occurring value is called the mode. Sometimes there is more than one mode. For example, in the data set\n\\[{1,~~2, ~~2, ~~2, ~~3, ~~4, ~~4, ~~5, ~~5, ~~5, ~~6}\\]\nthe modes are 2 and 5. Both of these values occur three times, which is more times than any other value.\nIf no number occurs more than once in the data set, we say that there is no mode. For the data set representing the costs to treat tuberculosis in India, none of the values is repeated. So, there is no mode for these data.\n\nAnswer the following question:\n\n\n\nFor a particular data set, which of the following can occur?\n\n\nThere may be no mode.\nThere may be exactly one mode.\nThere may be several modes.\nOnly A and B can occur.\nA, B, and C can all occur.\n\n\n\nShow/Hide Solution\n\n\nA, B, and C can all occur.\n\n\n\n\n\n\nExcel Instructions for Mean, Median, and Mode\n\nR Instructions\n\n\n\nTo calculate most numerical summaries (such as the mean, median, and mode) in Excel, follow these general steps:\n\nOpen R.\nEnter the data using the “assignment operator”, &lt;-, and c() which establishes a “collection” of things, in this case numbers.\n\nCalculate summary statisti\nThen, highlight the data (by clicking on it) to which you want to apply the function. The cell reference range will automatically be added to your formula. Then type a closed parenthesis, “)” and hit enter.\n\nCaculate a Mean\nFor example, to calculate the mean of the sample of tuberculosis patient costs in India:\n\n# Create a dataset called `data` with the costs from 10 randomly selected patients:\ndata &lt;- c(15100, 19000, 4800, 6500, 14900, 600, 23500, 11500,12900, 32200)\n\nmean(data)\n\n[1] 14100\n\n\n\nCalculate a Median\nSimply replace the word “mean” in the formula with the word “median”. Try it with the tuberculosis patient data, you should get the same value that was calculated by hand above.\n\nmedian(data)\n\n[1] 13900\n\n\n\nCalculate a Mode\nR makes it difficult to use the mode because there are fewer situations when it is useful for quantitative data where few values repeat. In the rare occasion we are not interested in a mean or median, we can tabulate the frequency of specific values using the table() function:\n\n# Create a new dataset called data2:\ndata2 &lt;- c(3,4,9,5,2,3,5,4,2,3,1,5,3,1,2,6,2,4,6,2,2,2,9,1,2,7,8)\n\n# The `table()` function counts up all the times specific values show up.  This works for numbers or categories:\ntable(data2)\n\ndata2\n1 2 3 4 5 6 7 8 9 \n3 8 4 3 3 2 1 1 2 \n\n\nThe first row of the table() output is the value being counted. The second row is the frequency of occurrence.\nWhich value is most frequently occurring?\nIf there are lots of occuring values, we can use R to sort() the table output to make it easier to see which is the mode:\n\nsort(table(data2))\n\ndata2\n7 8 6 9 1 4 5 3 2 \n1 1 2 2 3 3 3 4 8 \n\n\nThe rows are the same as before but are sorted in ascending order. We can now easily see that 2 occurred 8 times making 2 the mode.\n\n\n\nParameters and Statistics\nWe only have data on the cost to treat ten randomly selected tuberculosis patients. This represents a random sample from the population. The sample obtained by the researchers depends on random chance. If the study was repeated and a new sample of ten patients was randomly drawn from all cases of tuberculosis in India, would we observe the same data values? Certainly not!\nHowever, if we took a second random sample from the population, we would expect the mean of the new sample to be somewhat similar to the mean for our original sample. And if we took a third sample of data, we should expect the mean of this sample to be different than the means of the other two samples. In fact, every sample will give us a different sample mean, but all of these sample means will be fairly similar in value.\nOne of the primary purposes of collecting and analyzing data is to estimate the true mean of a population. Since collecting data on the entire population is usually not feasible, we usually never know what the true mean is. So we estimate the true population mean with the sample mean from a single sample of data from the population.\nThe sample mean is an example of a statistic. A statistic is a number that describes a sample. The true (usually unknown) population mean is an example of a parameter. A parameter is any number that describes a population.\nAn easy way to distinguish between a parameter and a statistic is to note the repetition in the first letters:\n\nPopulation Parameter True (usually unknown) value describing a population\nSample Statistic Estimate of the population parameter obtained from a sample\n\nIn the example above, the sample mean \\(\\bar x\\) = $14,100 is a statistic. Over the last few years, the total mean cost to treat tuberculosis in India has been $13,800. This $13,800 is considered a parameter because it is the “known” value for the full population.\nDifferent symbols are used to distinguish between the sample mean (a statistic) and the population mean (a parameter). The symbol for the sample mean is \\(\\bar x\\). The symbol for the population mean is \\(\\mu\\).\nPerspective\nThe mean cost to treat the ten tuberculosis patients in the sample was \\(\\bar x\\) = $14,100. This number gives us some useful information. However, if this was all we were given, we would not be able to distinguish the data above from a situation where the cost for each of the ten patients was exactly $14,100. Notice that if the cost for each patient was $14,100, the mean would be:\n\\[\\bar x=\\frac{14100 + 14100 + 14100 + 14100 + 14100 + 14100 + 14100 + 14100 + 14100 + 14100}{10} =14,100\\]\nEven though measures of center are important, we need to consider the shape, center and spread of a distribution of data. When evaluating data, it is sometimes tempting to compute a mean but to avoid creating a histogram. This can lead to errant decisions based on a misunderstanding or incorrect transcription of data. If there is a transcription error in the data, it is sometimes easiest to detect it as an outlier in a histogram."
  },
  {
    "objectID": "Textbook/Shape_and_Center.html#summary",
    "href": "Textbook/Shape_and_Center.html#summary",
    "title": "Describing Quantitative Data (Shape & Center)",
    "section": "Summary",
    "text": "Summary\n\nRemember…\n\n\n\n\nHistograms are created by dividing the number line into several equal parts, starting at or below the minimum value occurring in the data and ending at or above the maximum value in the data. The number of data points occurring in each interval (called a bin) are counted. A bar is then drawn for each bin so that the height of the bar shows the number of data points contained in that bin.\nA histogram allows us to visually interpret data to quickly recognize which values are most common and which values are least common in the data.\nHistograms can be left-skewed (the majority of the data is on the right of the histogram, less common values stretch to the left side), right-skewed (majority of the data is on the left side with less common values stretching to the right), or symmetrical and bell-shaped (most data is in the middle with less common values stretching out to either side).\nThe mean, median, and mode are measures of the center of a distribution. The mean is the most common measure of center and is computed by adding up the observed data and dividing by the number of observations in the data set. The median represents the 50th percentile in the data. The mean can be calculated in R using mean(...), the median by using median(...), and the mode by table(...) where the ... in each case consists of the data.\nWhen comparing the centers of distributions using graphical and numerical summaries, the direction of the skew showing in the histogram will generally correspond with the mean being pulled in that direction.\n\n\n\n\nRight-skewed\n\n\nSymmetric & Bell-shaped\n\n\nLeft-skewed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean: $10.45\nMedian: $9.04\nMean is to the right of the median.\n\n\nMean: 71.1 inches\nMedian: 71 inches\nMean and median are roughly equal.\n\n\nMean: 3.42\nMedian: 3.45\nMean is to the left of the median.\n\n\n\n\n\nIn a symmetrical and bell-shaped distribution of data, the mean, median, and mode are all roughly the same in value. However, in a skewed distribution, the mean is strongly influenced by outliers and tends to be pulled in the direction of the skew. In a left-skewed distribution, the mean will tend to be to the left of the median. In a right-skewed distribution, the mean will tend to be to the right of the median.\nA parameter is a true (but usually unknown) number that describes a population. A statistic is an estimate of a parameter obtained from a sample of the population."
  },
  {
    "objectID": "Textbook/Course_Introduction.html",
    "href": "Textbook/Course_Introduction.html",
    "title": "Course Introduction",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nExplain the course policies\nAccess course resources (course outline, lesson schedule, preparation activities, reading quizzes, homework assignments, assessments, etc.)\nCommunicate with the instructor and group members\nAccess statistical analysis software tools for class quizzes, assignments, and exams\nApply principles of the gospel of Jesus Christ in this class\nApply the three rules of probability for different probability scenarios"
  },
  {
    "objectID": "Textbook/Course_Introduction.html#lesson-outcomes",
    "href": "Textbook/Course_Introduction.html#lesson-outcomes",
    "title": "Course Introduction",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nExplain the course policies\nAccess course resources (course outline, lesson schedule, preparation activities, reading quizzes, homework assignments, assessments, etc.)\nCommunicate with the instructor and group members\nAccess statistical analysis software tools for class quizzes, assignments, and exams\nApply principles of the gospel of Jesus Christ in this class\nApply the three rules of probability for different probability scenarios"
  },
  {
    "objectID": "Textbook/Course_Introduction.html#welcome-to-the-course",
    "href": "Textbook/Course_Introduction.html#welcome-to-the-course",
    "title": "Course Introduction",
    "section": "Welcome to the Course!",
    "text": "Welcome to the Course!\nIn this course, you will explore important connections between the academic discipline of Statistics and the world around us. By pondering these ideas, your understanding of statistics will increase, as will your knowledge and testimony of the restored Gospel of Jesus Christ. In addition, that which you learn in this course will increase your ability to serve others as a disciple of Jesus Christ and help build Zion.\nThis course has been designed to help you slowly build up a knowledge base of ideas and skills. Not all of these ideas and skills will come easily. It takes a lot of work and practice before some things will even start to make sense, so you should not be surprised to find that it may take you a little time to comprehend these ideas. Just be patient. Once you’re far enough into the course, the ideas will start to come together, and you will see how much progress you have really made. You will understand what this course is all about, and you will be glad you persisted in your efforts to learn."
  },
  {
    "objectID": "Textbook/Course_Introduction.html#course-description",
    "href": "Textbook/Course_Introduction.html#course-description",
    "title": "Course Introduction",
    "section": "Course Description",
    "text": "Course Description\nThis course covers the following topics as they are applied to Statistics: graphical representations of data, measures of center and spread; elementary probability; sampling distributions; correlation and regression; statistical inference involving means, proportions, and contingency tables.\n\n\nCourse Learning Outcomes\nIn this course, we will:\n\nSummarize data numerically and graphically using spreadsheets\nMake decisions regarding situations with inherent randomness\nApply probability distributions to investigate questions\nEmploy confidence intervals in various situations\nImplement tests of diverse hypotheses\nCommunicate the results of statistical analyses to relevant audiences\n\n\n\n\nHow the Outcomes will Be Assessed\nWhile you may not be tested on everything you learn in this course, the instructor will be assessing your mastery of the Course Learning Outcomes. The general types of assessments used to measure these outcomes may include selected response tests such as multiple-choice, true-false, matching, and fill-in-the-blank questions. You may also be asked to complete essays or other writing assignments. At times, the instructor may assess your performance of a skill, or the instructor may assess products you create using particular skills. In addition, the instructor may engage in personal communication with you to determine how well you understand the course content.\n\n\n\nKeys to Success\n\nFive Principles of the Learning Model\nYou will experience much deeper learning if you follow the Five Principles of the BYU-Idaho Learning Model\n\nExercise Faith: Exercise faith in the Lord Jesus Christ as a principle of action and power.\nLearn by the Holy Ghost: Understand that true teaching is done by and with the Holy Ghost.\nLay Hold on the Word of God: Lay hold of the word of God.\nAct for Themselves: Act for yourself and accept responsibility for learning and teaching.\nLove, Serve, and Teach One Another: Love, serve, and teach other students in your classes.\n\n\n\nThree Process Steps of the Learning Model\nYou will learn more in less time if you follow the Three Process Steps of the BYU-Idaho Learning Model\n\nPrepare: This involves (a) spiritual preparation, (b) individual preparation, and (c) group preparation.\nTeach One Another: You should (a) be on time, (b) pray together, and (c) actively engage with other students.\nPonder/Prove: You should (a) ponder what you have learned, (b) record your learning, and (c) pursue unanswered questions and discuss what you learn with others.\n\nIf you feel confused or have questions about anything in the lesson, take immediate action (Exercise Faith; Act for Themselves) and talk with your classmates, the teaching assistant, or the instructor (Love, Serve, and Teach One Another).\nTeach One Another\nAt BYU-Idaho, an “A” student will demonstrate “diligent application of Learning Model principles, including initiative in serving other students” (BYU-Idaho Catalog). In this class, you will have the opportunity to work with other students.\nDoctrine and Covenants 84:106 states, “And if any man among you be strong in the Spirit, let him take with him him that is weak, that he may be edified in all meekness, that he may become strong also.” In the spirit of this revelation, you will have the opportunity to help others in the class when you have developed an understanding of a principle. Likewise, you will be able to receive help from others (peers, tutors, TA, and your instructor) when you are still working to understand concepts.\nIn a spirit of love and service, please reach out to others. You are not graded on a curve. If someone else does well, it does not affect you adversely. Research has shown that students who help other students to understand the material gain a much deeper grasp on the concepts of the course. Please take opportunities to help your peers succeed."
  },
  {
    "objectID": "Textbook/Course_Introduction.html#course-structure",
    "href": "Textbook/Course_Introduction.html#course-structure",
    "title": "Course Introduction",
    "section": "Course Structure",
    "text": "Course Structure\nThis course consists of 24 lessons. They are presented in a topical order in which concepts and skills learned in the earlier lessons provide the requisite knowledge to succeed in later lessons. If the general order of the lessons doesn’t make sense at first, don’t worry. It will all come together in the end, and you’ll see the reasoning behind why the lessons have been presented in this particular order.\nYour main goal as a student will be to complete all of the learning activities within each lesson by their due dates every week. These activities follow a consistent weekly schedule, and it will be up to you to make sure that you keep on pace with all your assignments. These weekly activities may include the following:\n\nReading assigned texts or viewing presentations.\nTaking quizzes.\nParticipating in group discussions and assignments with other class members.\nWriting papers and/or developing presentations.\nParticipating in meetings with the instructor, teaching assistants, and other students.\n\nFor many of these activities, the due dates will fall on the same time each week. This will make it easier for you to plan out your weekly study schedule. However, there may be a need to make adjustments to the schedule from time to time. If in doubt, refer to the due dates your instructor has posted in I-learn.\nYou should create a study schedule that will keep you on pace throughout the semester. This is a rigorous course with a lot of subject matter to cover, and it can be extremely difficult to recover if you fall too far behind in your work. So, please make every effort to study on a regular basis and get your work turned in on time.\nThe lessons in this course have a similar structure and contain similar basic elements. A typical week consists of two lessons. Each lesson will consist of a reading assignment, a reading/preparation quiz, and a homework quiz.\nThe structure of this course fully integrates the BYU-Idaho Learning model with a mixture of preparation activities, teach-one-another activities, and ponder-and-prove activities."
  },
  {
    "objectID": "Textbook/Course_Introduction.html#course-materials",
    "href": "Textbook/Course_Introduction.html#course-materials",
    "title": "Course Introduction",
    "section": "Course Materials",
    "text": "Course Materials\nThis course has been designed with the student in mind. Every effort has been made to provide a high quality experience at the lowest possible cost.\nTextbook\nTo keep costs as low as possible for students and their families, no physical textbook is required for this class. The readings for this course are provided on this website and will continue to be available to you after the course is completed. Please report any problems with the textbook (links not working, loading slowly, inability to view images, etc.) to your instructor. A link to the textbook is found in the Quick Links module. It is highly recommended you bookmark the textbook so that you can easily reference each lesson’s reading.\nComputer Equipment\nYou will need: - A laptop - Access to Microsoft Excel 2016 or later"
  },
  {
    "objectID": "Textbook/Course_Introduction.html#course-resources",
    "href": "Textbook/Course_Introduction.html#course-resources",
    "title": "Course Introduction",
    "section": "Course Resources",
    "text": "Course Resources\nPeer Support\nYour experience in this course will be enhanced as you work with other students to learn and grow together.\nHelp Desk\nThe BYU-Idaho Help Desk has been established to help students with technological problems related to approved course software. You can access the Help Desk at any time in three ways: - Walk-in: The Help Desk is located in room 322 of the McKay Library - Call in: 208-496-1411 (toll free) - Email: helpdesk@byui.edu Additional information is available at the Help Desk web page: http://www.byui.edu/helpdesk/\nWhen you have technical problems with I-Learn, you should first try contacting the Help Desk before you contact your instructor. They are connected with the IT support staff who can resolve problems with I-Learn. Please take a moment now to look at the Help Desk web page. That way, if a problem does arise later on in the course, you will know where to go for help.\nTutoring Center\nThe BYU-Idaho Study Skills/Tutoring Center is a powerful resource for students who would like a little extra help with a course. The Tutoring Center is located in the McKay Library in room 272. This is in the east wing of the second floor.\nThe Tutoring Center provides many services to help students succeed: - Individual tutors - Walk-in tutoring in the Math Study Center (McKay 266 & 270) - Virtual tutoring\nPlease take 5 minutes to explore the Study Skills/Tutoring Center web site.\nFaculty Support\nYour instructor is committed to your success. If you have any needs or concerns, please contact your instructor for help. If you feel yourself getting behind or struggling, talk to your teacher right away. If caught in time, a small problem can be addressed quickly before it grows.\nWith all of that said, let’s begin looking at a foundational idea of statistics: probability."
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "",
    "text": "In statistics classes, you are typically provided simple, clean datasets to load and analyze with ease. This is a terrible disservice to anyone who will deal with data outside of the classroom.\nAnyone who works with data will have to do some data wrangling. Data wrangling is an appropriate description of cleaning, sorting, filtering, summarizing, transforming, and a whole host of other activities to make data usable for a specific purpose.\nIn this document, we introduce a moderately messy dataset and demonstrate basic programming commands to help us get data ready for analysis or visualization."
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#additional-resources",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#additional-resources",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Additional Resources",
    "text": "Additional Resources\nBelow are 2 great resources for digging a little deeper into data manipulation in R.\nTidyverse Cheat Sheet\nR for Data Science\nNext, we will explain a few programming fundamentals that will help make"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#logical-operators",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#logical-operators",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Logical Operators",
    "text": "Logical Operators\nLogical operators are used extensively in computer programming to determine if a certain condition is met. They always return a “True” or a “False”, but we can treat them like a 0 for false and 1 for true.\nWe can tell a computer to determine a conditional statement (typically “less than”, “greater than” or “not equal to”) for specific variables, and it will return a TRUE if the statement is true and FALSE if not.\n\nQuantitative Variables\nLet’s examine the height_cm column in the survey data.\n\n\nCode\nfavstats(survey$Height_cm)\n\n\n  min  Q1 median      Q3 max     mean       sd   n missing\n 1.68 161    170 178.125 999 169.2412 53.54382 312       0\n\n\nCode\nhist(survey$Height_cm)\n\n\n\n\n\n\n\n\n\nThe maximum is 999 cm, which is around 33 Feet! We know this is not a possible value.\nIt is very unlikely that a high school student is taller than 7 feet. We can use a logical operator to see which students are taller than 7 feet (213.36 cm):\n\n\nCode\nsurvey$Height_cm &gt; 213.36\n\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[121] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[169] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[193] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[205] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[217] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[229] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[241] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[253] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[265] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[277] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[289] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[301] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nCode\n# To illustrate, the below code puts the Survey column, Height_cm, along with the TRUE/FALSE logical\ndata.frame(Height_cm =survey$Height_cm, logical = survey$Height_cm &gt; 213.36)[73:84,]\n\n\n   Height_cm logical\n73     162.0   FALSE\n74     172.0   FALSE\n75     160.0   FALSE\n76     175.0   FALSE\n77     182.8   FALSE\n78     153.0   FALSE\n79     184.0   FALSE\n80     170.0   FALSE\n81     150.0   FALSE\n82     177.8   FALSE\n83     999.0    TRUE\n84     172.7   FALSE\n\n\nWhat does the above code return?\nA list of TRUE and FALSE for every line of the data. It is as long as the number of rows in the dataset.\n\n\nCategorical Variables\nWe can also use logical operators for categorical data. For example, if we wanted to see how many people are ambidextrous, we can run the following:\n\n\nCode\n# What are unique values in of the respondents?\n\nunique(survey$Handed)\n\n\n[1] \"Left-Handed\"  \"Right-Handed\" \"Ambidextrous\"\n\n\nCode\n# Use a logical operator to get TRUE and FALSE for students who responded \"Ambidextrous\" on the survey question about handedness\n\nsum(survey$Handed == \"Ambidextrous\")\n\n\n[1] 9\n\n\nCode\ndata.frame(Handed = survey$Handed, logical = survey$Handed == 'Ambidextrous')\n\n\n          Handed logical\n1    Left-Handed   FALSE\n2   Right-Handed   FALSE\n3   Right-Handed   FALSE\n4   Right-Handed   FALSE\n5    Left-Handed   FALSE\n6   Right-Handed   FALSE\n7   Ambidextrous    TRUE\n8   Right-Handed   FALSE\n9   Right-Handed   FALSE\n10  Right-Handed   FALSE\n11  Right-Handed   FALSE\n12   Left-Handed   FALSE\n13  Right-Handed   FALSE\n14  Right-Handed   FALSE\n15  Right-Handed   FALSE\n16  Right-Handed   FALSE\n17  Right-Handed   FALSE\n18  Right-Handed   FALSE\n19  Right-Handed   FALSE\n20   Left-Handed   FALSE\n21  Right-Handed   FALSE\n22   Left-Handed   FALSE\n23  Right-Handed   FALSE\n24  Right-Handed   FALSE\n25  Right-Handed   FALSE\n26  Right-Handed   FALSE\n27  Right-Handed   FALSE\n28  Ambidextrous    TRUE\n29  Right-Handed   FALSE\n30  Right-Handed   FALSE\n31  Right-Handed   FALSE\n32  Right-Handed   FALSE\n33  Right-Handed   FALSE\n34  Right-Handed   FALSE\n35   Left-Handed   FALSE\n36  Right-Handed   FALSE\n37  Right-Handed   FALSE\n38   Left-Handed   FALSE\n39  Right-Handed   FALSE\n40  Right-Handed   FALSE\n41  Right-Handed   FALSE\n42  Right-Handed   FALSE\n43  Right-Handed   FALSE\n44  Right-Handed   FALSE\n45  Right-Handed   FALSE\n46  Right-Handed   FALSE\n47  Right-Handed   FALSE\n48  Ambidextrous    TRUE\n49  Right-Handed   FALSE\n50  Right-Handed   FALSE\n51  Right-Handed   FALSE\n52  Right-Handed   FALSE\n53  Right-Handed   FALSE\n54  Right-Handed   FALSE\n55  Right-Handed   FALSE\n56   Left-Handed   FALSE\n57  Right-Handed   FALSE\n58  Right-Handed   FALSE\n59  Right-Handed   FALSE\n60  Right-Handed   FALSE\n61  Right-Handed   FALSE\n62  Right-Handed   FALSE\n63  Right-Handed   FALSE\n64  Right-Handed   FALSE\n65  Right-Handed   FALSE\n66  Right-Handed   FALSE\n67  Right-Handed   FALSE\n68  Right-Handed   FALSE\n69  Right-Handed   FALSE\n70  Right-Handed   FALSE\n71  Right-Handed   FALSE\n72  Right-Handed   FALSE\n73  Right-Handed   FALSE\n74   Left-Handed   FALSE\n75   Left-Handed   FALSE\n76  Right-Handed   FALSE\n77  Right-Handed   FALSE\n78  Right-Handed   FALSE\n79  Right-Handed   FALSE\n80   Left-Handed   FALSE\n81  Right-Handed   FALSE\n82   Left-Handed   FALSE\n83  Ambidextrous    TRUE\n84  Right-Handed   FALSE\n85  Right-Handed   FALSE\n86   Left-Handed   FALSE\n87  Right-Handed   FALSE\n88  Right-Handed   FALSE\n89   Left-Handed   FALSE\n90  Right-Handed   FALSE\n91   Left-Handed   FALSE\n92  Right-Handed   FALSE\n93  Right-Handed   FALSE\n94  Right-Handed   FALSE\n95  Right-Handed   FALSE\n96  Right-Handed   FALSE\n97  Right-Handed   FALSE\n98  Right-Handed   FALSE\n99  Right-Handed   FALSE\n100 Right-Handed   FALSE\n101 Right-Handed   FALSE\n102 Right-Handed   FALSE\n103 Right-Handed   FALSE\n104 Right-Handed   FALSE\n105 Right-Handed   FALSE\n106 Right-Handed   FALSE\n107 Right-Handed   FALSE\n108 Right-Handed   FALSE\n109 Right-Handed   FALSE\n110 Right-Handed   FALSE\n111 Right-Handed   FALSE\n112 Right-Handed   FALSE\n113 Right-Handed   FALSE\n114 Right-Handed   FALSE\n115 Right-Handed   FALSE\n116 Right-Handed   FALSE\n117 Right-Handed   FALSE\n118 Right-Handed   FALSE\n119 Right-Handed   FALSE\n120 Right-Handed   FALSE\n121 Right-Handed   FALSE\n122 Right-Handed   FALSE\n123 Right-Handed   FALSE\n124 Right-Handed   FALSE\n125 Right-Handed   FALSE\n126 Right-Handed   FALSE\n127 Right-Handed   FALSE\n128 Right-Handed   FALSE\n129 Right-Handed   FALSE\n130 Right-Handed   FALSE\n131  Left-Handed   FALSE\n132 Right-Handed   FALSE\n133 Right-Handed   FALSE\n134 Right-Handed   FALSE\n135 Right-Handed   FALSE\n136 Right-Handed   FALSE\n137 Right-Handed   FALSE\n138 Right-Handed   FALSE\n139 Right-Handed   FALSE\n140 Right-Handed   FALSE\n141 Right-Handed   FALSE\n142 Right-Handed   FALSE\n143 Ambidextrous    TRUE\n144 Right-Handed   FALSE\n145 Right-Handed   FALSE\n146 Right-Handed   FALSE\n147 Right-Handed   FALSE\n148 Right-Handed   FALSE\n149  Left-Handed   FALSE\n150 Right-Handed   FALSE\n151 Right-Handed   FALSE\n152 Right-Handed   FALSE\n153 Right-Handed   FALSE\n154 Right-Handed   FALSE\n155 Right-Handed   FALSE\n156 Right-Handed   FALSE\n157 Right-Handed   FALSE\n158 Right-Handed   FALSE\n159 Right-Handed   FALSE\n160 Right-Handed   FALSE\n161 Right-Handed   FALSE\n162 Right-Handed   FALSE\n163  Left-Handed   FALSE\n164 Right-Handed   FALSE\n165 Right-Handed   FALSE\n166 Right-Handed   FALSE\n167  Left-Handed   FALSE\n168 Right-Handed   FALSE\n169  Left-Handed   FALSE\n170  Left-Handed   FALSE\n171 Right-Handed   FALSE\n172 Right-Handed   FALSE\n173 Right-Handed   FALSE\n174 Right-Handed   FALSE\n175 Right-Handed   FALSE\n176 Right-Handed   FALSE\n177 Right-Handed   FALSE\n178 Right-Handed   FALSE\n179 Right-Handed   FALSE\n180 Right-Handed   FALSE\n181 Right-Handed   FALSE\n182 Right-Handed   FALSE\n183 Right-Handed   FALSE\n184 Right-Handed   FALSE\n185 Ambidextrous    TRUE\n186 Right-Handed   FALSE\n187 Right-Handed   FALSE\n188 Right-Handed   FALSE\n189 Right-Handed   FALSE\n190 Right-Handed   FALSE\n191 Right-Handed   FALSE\n192 Right-Handed   FALSE\n193 Right-Handed   FALSE\n194 Right-Handed   FALSE\n195 Right-Handed   FALSE\n196 Right-Handed   FALSE\n197 Right-Handed   FALSE\n198 Right-Handed   FALSE\n199 Right-Handed   FALSE\n200 Right-Handed   FALSE\n201 Right-Handed   FALSE\n202 Right-Handed   FALSE\n203 Right-Handed   FALSE\n204 Right-Handed   FALSE\n205 Right-Handed   FALSE\n206  Left-Handed   FALSE\n207 Ambidextrous    TRUE\n208 Right-Handed   FALSE\n209 Ambidextrous    TRUE\n210 Right-Handed   FALSE\n211 Right-Handed   FALSE\n212 Right-Handed   FALSE\n213 Right-Handed   FALSE\n214 Right-Handed   FALSE\n215 Right-Handed   FALSE\n216 Right-Handed   FALSE\n217 Right-Handed   FALSE\n218 Right-Handed   FALSE\n219 Right-Handed   FALSE\n220 Right-Handed   FALSE\n221 Right-Handed   FALSE\n222 Right-Handed   FALSE\n223 Right-Handed   FALSE\n224  Left-Handed   FALSE\n225  Left-Handed   FALSE\n226 Right-Handed   FALSE\n227 Right-Handed   FALSE\n228 Right-Handed   FALSE\n229 Right-Handed   FALSE\n230 Right-Handed   FALSE\n231 Right-Handed   FALSE\n232 Right-Handed   FALSE\n233 Right-Handed   FALSE\n234 Right-Handed   FALSE\n235 Right-Handed   FALSE\n236  Left-Handed   FALSE\n237 Right-Handed   FALSE\n238  Left-Handed   FALSE\n239 Right-Handed   FALSE\n240  Left-Handed   FALSE\n241 Right-Handed   FALSE\n242 Right-Handed   FALSE\n243 Right-Handed   FALSE\n244  Left-Handed   FALSE\n245 Right-Handed   FALSE\n246 Right-Handed   FALSE\n247 Right-Handed   FALSE\n248 Right-Handed   FALSE\n249 Right-Handed   FALSE\n250 Right-Handed   FALSE\n251  Left-Handed   FALSE\n252 Right-Handed   FALSE\n253 Right-Handed   FALSE\n254 Right-Handed   FALSE\n255 Right-Handed   FALSE\n256 Right-Handed   FALSE\n257 Right-Handed   FALSE\n258 Right-Handed   FALSE\n259 Right-Handed   FALSE\n260 Right-Handed   FALSE\n261 Right-Handed   FALSE\n262 Right-Handed   FALSE\n263 Right-Handed   FALSE\n264 Right-Handed   FALSE\n265 Right-Handed   FALSE\n266 Right-Handed   FALSE\n267 Right-Handed   FALSE\n268 Right-Handed   FALSE\n269 Right-Handed   FALSE\n270 Right-Handed   FALSE\n271 Right-Handed   FALSE\n272 Right-Handed   FALSE\n273 Right-Handed   FALSE\n274 Right-Handed   FALSE\n275 Right-Handed   FALSE\n276  Left-Handed   FALSE\n277 Right-Handed   FALSE\n278 Right-Handed   FALSE\n279 Right-Handed   FALSE\n280  Left-Handed   FALSE\n281 Right-Handed   FALSE\n282 Right-Handed   FALSE\n283 Right-Handed   FALSE\n284 Right-Handed   FALSE\n285  Left-Handed   FALSE\n286 Right-Handed   FALSE\n287 Right-Handed   FALSE\n288 Ambidextrous    TRUE\n289  Left-Handed   FALSE\n290 Right-Handed   FALSE\n291  Left-Handed   FALSE\n292 Right-Handed   FALSE\n293 Right-Handed   FALSE\n294 Right-Handed   FALSE\n295 Right-Handed   FALSE\n296 Right-Handed   FALSE\n297 Right-Handed   FALSE\n298 Right-Handed   FALSE\n299  Left-Handed   FALSE\n300 Right-Handed   FALSE\n301 Right-Handed   FALSE\n302 Right-Handed   FALSE\n303 Right-Handed   FALSE\n304 Right-Handed   FALSE\n305 Right-Handed   FALSE\n306 Right-Handed   FALSE\n307  Left-Handed   FALSE\n308 Right-Handed   FALSE\n309 Right-Handed   FALSE\n310 Right-Handed   FALSE\n311 Right-Handed   FALSE\n312 Right-Handed   FALSE\n\n\nWe will show you why this is useful when we introduce tidyverse functions."
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#ceci-nest-pas-une-pipe",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#ceci-nest-pas-une-pipe",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Ceci n’est pas une pipe",
    "text": "Ceci n’est pas une pipe\nThe tidyverse organizes actions to data sequentially. We separate steps by what is called a “pipe” which is programmed %&gt;%.\nHINT: The shortkey for adding a “pipe” is ctrl+shift+m for Windows, and cmd+shift+m on Mac. Learn this because we use them a lot!"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#removing-rows---filter",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#removing-rows---filter",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Removing Rows - filter()",
    "text": "Removing Rows - filter()\nLogical operators are useful when removing rows from a dataset. The most common logical operators used to filter rows are:\n\n&lt; and &lt;= means “less than” and “less than or equal to” respectively\n&gt; and &gt;= means “greater than” and “greater than or equal to” respectively\n== means “equal to” (NOTE: we use double equals because in most computer languages, a single = is an assignment operator. This avoids ambiguity)\n!= means “not equal to”; this one is useful if you want to eliminate one level of a variable\n%in% is useful for defining a list of levels that you want to include\n\nWe typically begin with the raw dataset, then “pipe” that dataset into a sequence of functions using the “pipe” operator, %&gt;%.\nLet’s begin by filtering out rows we think have legitimate heights:\n\n\nCode\nsurvey %&gt;% \n  filter(Height_cm &lt; 214)\n\n\n# A tibble: 310 × 60\n   Country Region DataYear ClassGrade Gender Ageyears Handed       Height_cm\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 USA     FL         2022         12 Male         18 Left-Handed        182\n 2 USA     IN         2022         12 Male         17 Right-Handed       190\n 3 USA     GA         2022         12 Female       17 Right-Handed       172\n 4 USA     NC         2022         11 Female       15 Right-Handed       163\n 5 USA     CO         2022         12 Female       17 Left-Handed         51\n 6 USA     MO         2022         11 Male         17 Right-Handed       181\n 7 USA     NC         2022         11 Male         17 Ambidextrous       175\n 8 USA     SC         2022         11 Female       18 Right-Handed       160\n 9 USA     WA         2022         11 Female       16 Right-Handed       156\n10 USA     WA         2022         12 Female       17 Right-Handed       169\n# ℹ 300 more rows\n# ℹ 52 more variables: Footlength_cm &lt;dbl&gt;, Armspan_cm &lt;dbl&gt;,\n#   Languages_spoken &lt;dbl&gt;, Travel_to_School &lt;chr&gt;,\n#   Travel_time_to_School &lt;int&gt;, Reaction_time &lt;dbl&gt;,\n#   Score_in_memory_game &lt;dbl&gt;, Favourite_physical_activity &lt;chr&gt;,\n#   Imprtance_reducing_pllutin &lt;int&gt;, Imprtance_recycling_rubbish &lt;int&gt;,\n#   Imprtance_cnserving_water &lt;int&gt;, Imprtance_saving_energy &lt;int&gt;, …\n\n\nThe above code will return a new dataset without the outliers.\nHow many rows does the original dataset have?\nHow many rows does the filtered dataset have?\nSuppose for some reason, we only want to include right- or left-handed people (excluding ambidextrous). We can add multiple conditions in the filter() function separated by a comma:\n\n\nCode\nunique(survey$Handed)\n\n\n[1] \"Left-Handed\"  \"Right-Handed\" \"Ambidextrous\"\n\n\nCode\nsurvey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\")\n\n\n# A tibble: 302 × 60\n   Country Region DataYear ClassGrade Gender Ageyears Handed       Height_cm\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 USA     FL         2022         12 Male         18 Left-Handed        182\n 2 USA     IN         2022         12 Male         17 Right-Handed       190\n 3 USA     GA         2022         12 Female       17 Right-Handed       172\n 4 USA     NC         2022         11 Female       15 Right-Handed       163\n 5 USA     CO         2022         12 Female       17 Left-Handed         51\n 6 USA     MO         2022         11 Male         17 Right-Handed       181\n 7 USA     SC         2022         11 Female       18 Right-Handed       160\n 8 USA     WA         2022         11 Female       16 Right-Handed       156\n 9 USA     WA         2022         12 Female       17 Right-Handed       169\n10 USA     WA         2022         11 Male         18 Right-Handed       160\n# ℹ 292 more rows\n# ℹ 52 more variables: Footlength_cm &lt;dbl&gt;, Armspan_cm &lt;dbl&gt;,\n#   Languages_spoken &lt;dbl&gt;, Travel_to_School &lt;chr&gt;,\n#   Travel_time_to_School &lt;int&gt;, Reaction_time &lt;dbl&gt;,\n#   Score_in_memory_game &lt;dbl&gt;, Favourite_physical_activity &lt;chr&gt;,\n#   Imprtance_reducing_pllutin &lt;int&gt;, Imprtance_recycling_rubbish &lt;int&gt;,\n#   Imprtance_cnserving_water &lt;int&gt;, Imprtance_saving_energy &lt;int&gt;, …\n\n\nCode\n# Equivalently we can use %in% instead of the !=\n\nsurvey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed %in% c(\"Left-Handed\", \"Right-Handed\"),\n         Region %in% c(\"MO\", \"FL\"))\n\n\n# A tibble: 27 × 60\n   Country Region DataYear ClassGrade Gender Ageyears Handed       Height_cm\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 USA     FL         2022         12 Male         18 Left-Handed       182 \n 2 USA     MO         2022         11 Male         17 Right-Handed      181 \n 3 USA     MO         2022         11 Female       17 Right-Handed      151 \n 4 USA     FL         2022         12 Female       18 Right-Handed      170 \n 5 USA     FL         2022         12 Male         18 Right-Handed      180 \n 6 USA     FL         2022         12 Female       18 Right-Handed      173.\n 7 USA     FL         2022         12 Male         18 Right-Handed      175 \n 8 USA     FL         2022         12 Male         17 Right-Handed      180 \n 9 USA     MO         2022         11 Male         17 Right-Handed      164 \n10 USA     FL         2022         12 Female       17 Right-Handed      166 \n# ℹ 17 more rows\n# ℹ 52 more variables: Footlength_cm &lt;dbl&gt;, Armspan_cm &lt;dbl&gt;,\n#   Languages_spoken &lt;dbl&gt;, Travel_to_School &lt;chr&gt;,\n#   Travel_time_to_School &lt;int&gt;, Reaction_time &lt;dbl&gt;,\n#   Score_in_memory_game &lt;dbl&gt;, Favourite_physical_activity &lt;chr&gt;,\n#   Imprtance_reducing_pllutin &lt;int&gt;, Imprtance_recycling_rubbish &lt;int&gt;,\n#   Imprtance_cnserving_water &lt;int&gt;, Imprtance_saving_energy &lt;int&gt;, …\n\n\nCode\nsurvey$Handed %in% c(\"Left-Handed\", \"Right-Handed\")\n\n\n  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [25]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n [49]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [61]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [73]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[109]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[121]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[133]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE\n[145]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[157]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[169]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[181]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[193]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[205]  TRUE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[217]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[229]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[241]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[253]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[265]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[277]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n[289]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[301]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nHow many rows does our latest dataset have?"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#adding-columns---mutate",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#adding-columns---mutate",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Adding Columns - mutate()",
    "text": "Adding Columns - mutate()\nThe mutate() statement is used to add new columns to a dataset.\nTo create a new column, “pipe” the previous steps into the mutate() statement. Inside the parentheses, give the new column a name and set it equal to what you want that column to be.\nEXAMPLE: Create a column of the ratio of Height to armspan called, ht_to_span, by using a mutate() statement:\n\n\nCode\nclean &lt;- survey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\") %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm,\n         ht_in = Height_cm / 2.54) %&gt;%\n  select(Handed, ht_to_span, ht_in)\n\nView(clean)\n\n\nNotice we no longer have to use $ to access specific columns! The tidyverse lives up to its name!"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#selecting-columns---select",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#selecting-columns---select",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Selecting Columns - select()",
    "text": "Selecting Columns - select()\nThere are now over 60 columns in this dataset. Suppose we are only interested in reaction times and height-to-armspan ratio as they related to handedness. To tidy up the data even further, select only the columns we are interested in (Handed, Reaction_time, and ht_to_span):\n\n\nCode\nsurvey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\") %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span)\n\n\n# A tibble: 302 × 3\n   Handed       Reaction_time ht_to_span\n   &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;\n 1 Left-Handed          0.349      1.28 \n 2 Right-Handed         0.358      0.990\n 3 Right-Handed         0.447      1.03 \n 4 Right-Handed         0.438      1.02 \n 5 Left-Handed          0.542      0.981\n 6 Right-Handed         0.428      0.968\n 7 Right-Handed         0.427      1.01 \n 8 Right-Handed         0.412      1.10 \n 9 Right-Handed         0.346      1.04 \n10 Right-Handed         0.391      1    \n# ℹ 292 more rows\n\n\nSee how much we can do in just a few short, sequential lines of code? Let’s name out clean dataset, clean, and create a boxplot of reaction times comparing left and right handed students:\n\n\nCode\nclean &lt;- survey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\") %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span)\n\nboxplot(clean$Reaction_time ~ clean$Handed)\n\n# Modify the code to remove outliers in Reaction_time and remake the boxplot\n\nclean &lt;- survey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\") %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span)\n\nboxplot(clean$Reaction_time ~ clean$Handed)"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#summarising-data---group_by-summarise",
    "href": "10-Intro_to_Data_Wrangling/Tidyverse_Fundamentals.html#summarising-data---group_by-summarise",
    "title": "Introducing the Tidyverse - Part 1",
    "section": "Summarising Data - group_by() + summarise()",
    "text": "Summarising Data - group_by() + summarise()\nThe above data might be adequate for a visualization or analysis, but we can calculate summary statistics tables like we did with favstats() using the tidyverse.\nThe summarise() (or equivalently, summarize()) function is like the mutate statement. We create a name for the new column and set it equal to what we want.\nLet’s name the new dataset, clean, and see how to make summaries using tidyverse.\n\n\nCode\nboxplot(survey$Reaction_time)\n\n\n\n\n\n\n\n\n\nCode\nclean &lt;- survey %&gt;%\n  filter(Height_cm &lt; 214, \n         Handed != \"Ambidextrous\", \n         Reaction_time &lt; 1,\n         Armspan_cm &gt; 0,\n         ClassGrade == 12) %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span)\n\nboxplot(clean$Reaction_time ~ clean$Handed)\n\n\n\n\n\n\n\n\n\nCode\nclean %&gt;%\n  summarise(\n    mn_react_time = mean(Reaction_time, na.rm=TRUE),\n    med_react_time = median(Reaction_time, na.rm=TRUE),\n    mn_ratio = mean(ht_to_span, na.rm=TRUE)\n  )\n\n\n# A tibble: 1 × 3\n  mn_react_time med_react_time mn_ratio\n          &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n1         0.397          0.366     1.27\n\n\nNotice that the mn_ratio is Inf.\nWhy might that be the case?\nModify the code chunk to exclude rows where arm span is 0:\n\n\nCode\nclean &lt;- survey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\",\n         Reaction_time &lt; 1) %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span)\n\n\n\nclean %&gt;%\n  summarise(\n    `Mean Reaction Time` = mean(Reaction_time, na.rm=TRUE),\n    med_react_time = median(Reaction_time, na.rm=TRUE),\n    mn_ratio = mean(ht_to_span, na.rm=TRUE),\n    min_react_time = min(Reaction_time, na.rm=TRUE)\n  ) %&gt;% knitr::kable()\n\n\n\n\n\nMean Reaction Time\nmed_react_time\nmn_ratio\nmin_react_time\n\n\n\n\n0.4205068\n0.388\nInf\n0.067\n\n\n\n\n\nCode\nfavstats(clean$Reaction_time ~ clean$Handed)\n\n\n  clean$Handed   min      Q1 median      Q3   max      mean        sd   n\n1  Left-Handed 0.274 0.34825 0.4415 0.53850 0.895 0.4741471 0.1691585  34\n2 Right-Handed 0.067 0.33825 0.3845 0.44775 0.995 0.4134380 0.1302318 258\n  missing\n1       0\n2       0\n\n\nCode\nfavstats(clean$ht_to_span)\n\n\n    min        Q1   median       Q3 max mean  sd   n missing\n 0.0168 0.9841579 1.006519 1.052681 Inf  Inf NaN 292       0\n\n\nIf we want to get means for separate groups, we can add a group_by() statement to tell which variable(s) we want to group by:\n\n\nCode\nclean &lt;- survey %&gt;%\n  filter(Height_cm &lt; 214,\n         Handed != \"Ambidextrous\",\n         Reaction_time &lt; 1,\n         Armspan_cm &gt; 0) %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span)\n\n\n\nclean %&gt;%\n  group_by(Handed) %&gt;%\n  summarise(\n    mn_react_time = mean(Reaction_time, na.rm=TRUE),\n    med_react_time = median(Reaction_time, na.rm=TRUE),\n    mn_ratio = mean(ht_to_span, na.rm=TRUE),\n    max_react = max(Reaction_time),\n    count = n()\n  ) %&gt;%\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nHanded\nmn_react_time\nmed_react_time\nmn_ratio\nmax_react\ncount\n\n\n\n\nLeft-Handed\n0.4741471\n0.4415\n1.266468\n0.895\n34\n\n\nRight-Handed\n0.4133891\n0.3840\n1.260190\n0.995\n257\n\n\n\n\n\nThe n() is very useful for counting up the number of observations in each group.\nIf we were only interested in the summary statistics table, we can do everything in one series of steps:\n\n\nCode\nsummary_stats_table &lt;-  survey %&gt;%\n  filter(\n    Height_cm &lt; 214,\n    Handed != \"Ambidextrous\",\n    Reaction_time &lt; 1,\n    Armspan_cm &gt; 0) %&gt;%\n  mutate(ht_to_span = Height_cm / Armspan_cm) %&gt;%\n  select(Handed, Reaction_time, ht_to_span) %&gt;%\n  group_by(Handed) %&gt;%\n  summarise(\n    mn_react_time = mean(Reaction_time, na.rm=TRUE),\n    med_react_time = median(Reaction_time, na.rm=TRUE),\n    mn_ratio = mean(ht_to_span, na.rm=TRUE),\n    max_react = max(Reaction_time),\n    count = n()\n  )\n\nsummary_stats_table\n\n\n# A tibble: 2 × 6\n  Handed       mn_react_time med_react_time mn_ratio max_react count\n  &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n1 Left-Handed          0.474          0.442     1.27     0.895    34\n2 Right-Handed         0.413          0.384     1.26     0.995   257"
  },
  {
    "objectID": "04-Intro_to_R/Introducing_R_Homework.html#calculate-the-summary-statistics-for-duration",
    "href": "04-Intro_to_R/Introducing_R_Homework.html#calculate-the-summary-statistics-for-duration",
    "title": "Introducing R",
    "section": "Calculate the Summary Statistics for Duration",
    "text": "Calculate the Summary Statistics for Duration\nWhat is the mean duration time of Old Faithful eruptions?\nWhat is the standard deviation of duration?"
  },
  {
    "objectID": "04-Intro_to_R/Introducing_R_Homework.html#create-a-historgram-for-duration",
    "href": "04-Intro_to_R/Introducing_R_Homework.html#create-a-historgram-for-duration",
    "title": "Introducing R",
    "section": "Create a Historgram for Duration",
    "text": "Create a Historgram for Duration\nCreate a histogram and describe the shape of the distribution of duration:"
  },
  {
    "objectID": "04-Intro_to_R/Introducing_R_Homework.html#calculate-summary-statistics-for-wait-time",
    "href": "04-Intro_to_R/Introducing_R_Homework.html#calculate-summary-statistics-for-wait-time",
    "title": "Introducing R",
    "section": "Calculate Summary Statistics for Wait time",
    "text": "Calculate Summary Statistics for Wait time\nWhat is the mean wait time between eruptions?\nWhat is the maximum wait time between eruptions?\nThe middle 50% of wait times will be between what 2 numbers?"
  },
  {
    "objectID": "01-Course_Intro/Installing_R.html",
    "href": "01-Course_Intro/Installing_R.html",
    "title": "Installing R",
    "section": "",
    "text": "In this course, we will use R and RStudio to perform necessary calculations. This will allow us to focus on the statistical principles.\nIf you have not already installed R and RStudio on your computer, please follow these instructions to do so.\n\nInstall R: Install the latest version of R link\nInstall RStudio: (Mac OS X | PC)\n\nIf you are using a Chromebook or other “web browsing only” computer that will not allow you to install software, then set up an account at RStudio Cloud instead of installing R and RStudio as shown here. Use your BYU-I\nJust accept all of the default options when installing.\n\n\nTo install the statistical analysis program RStudio you will first need to install a piece of software called R. Funny name, right? (There was originally a software called “S” for statistics, and then “R” was invented later on. Part of the reason they used “R” was to claim that “R” was a “leap ahead” of “S.”)\nInstall the R Software by clicking:\n\nMac OS X M1-3 Chip (Most Common)\nMac OS X Intel Chip\nPC\n\nOnce that download finishes, open the resulting file.\nClick “Continue” or “Okay” or “Accept” for all of the several various windows that will appear.\nNow that R is properly installed on your computer, we need to install RStudio. RStudio is an app that runs R inside of it and provides you with many other tools that go way beyond what R can do. This is why R must be installed first, so that RStudio can use it. You will never need to open R yourself. Just use RStudio. But without R, RStudio won’t work properly.\nInstall the RStudio app by clicking here: (Mac OS X | Windows).\nOnce the RStudio installer downloads, open the resulting file.\nAgain, work through the installation process, agreeing with all the defaults and terms of conditions.\nOnce the installation finishes you can use your computer’s search bar to search for “RStudio” in your apps."
  },
  {
    "objectID": "01-Course_Intro/Installing_R.html#detailed-instructions",
    "href": "01-Course_Intro/Installing_R.html#detailed-instructions",
    "title": "Installing R",
    "section": "",
    "text": "To install the statistical analysis program RStudio you will first need to install a piece of software called R. Funny name, right? (There was originally a software called “S” for statistics, and then “R” was invented later on. Part of the reason they used “R” was to claim that “R” was a “leap ahead” of “S.”)\nInstall the R Software by clicking:\n\nMac OS X M1-3 Chip (Most Common)\nMac OS X Intel Chip\nPC\n\nOnce that download finishes, open the resulting file.\nClick “Continue” or “Okay” or “Accept” for all of the several various windows that will appear.\nNow that R is properly installed on your computer, we need to install RStudio. RStudio is an app that runs R inside of it and provides you with many other tools that go way beyond what R can do. This is why R must be installed first, so that RStudio can use it. You will never need to open R yourself. Just use RStudio. But without R, RStudio won’t work properly.\nInstall the RStudio app by clicking here: (Mac OS X | Windows).\nOnce the RStudio installer downloads, open the resulting file.\nAgain, work through the installation process, agreeing with all the defaults and terms of conditions.\nOnce the installation finishes you can use your computer’s search bar to search for “RStudio” in your apps."
  },
  {
    "objectID": "01-Course_Intro/Installing_R.html#mac-processing-chip",
    "href": "01-Course_Intro/Installing_R.html#mac-processing-chip",
    "title": "Installing R",
    "section": "Mac Processing Chip",
    "text": "Mac Processing Chip\nFor Macs, Which version of R-Studio you download depends on which processing chip you have. If you followed the instructions above and R-Studio opens but gives you a big error, you need to download the other version of R linked above."
  },
  {
    "objectID": "01-Course_Intro/TestingTesting.html",
    "href": "01-Course_Intro/TestingTesting.html",
    "title": "Testing…Testing…1…2…3",
    "section": "",
    "text": "Introduction\nThis type of file is called a “markdown” file. Markdown is like Microsoft Word but much more powerful. This file is made specific for R, and has a file type .Rmd meaning “R Markdown”.\nYou will become very familiar with these files throughout the semester. For now, it’s only necessary to download this file, save it in a sensible folder on your computer or OneDrive, and “run” it.\nClicking on the “knit” button above (depending on your computer setup it may show up shows up “Render”) will create an .html document that should open up in your default browser.\nAs you see, we can make section headers and type regular text. But the power of .Rmd files is that we can also code inside these documents and present our output directly within the document.\nClick “Knit” or “Render” to test to see if your software is set up.\nWhen coding, we have to tell the computer when we’re writing text and when we expect it to compile code. Below is an example of a “code chunk” that creates a made up graph.\nYou do not have to understand this right now. We’re only testing that R and RStudio are set up correctly.\n\n\nCode\nx &lt;- seq(0,10, length = 100)\ny &lt;- 2+exp(x)\n\nplot(x,y, type = \"l\", lwd=2, col=\"darkblue\", main = \"Exponential Function\")"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Exploring_New_Data_with_Tidyverse.html",
    "href": "10-Intro_to_Data_Wrangling/Exploring_New_Data_with_Tidyverse.html",
    "title": "Happiness in the Tidyverse",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = TRUE)"
  },
  {
    "objectID": "10-Intro_to_Data_Wrangling/Exploring_New_Data_with_Tidyverse.html#lying",
    "href": "10-Intro_to_Data_Wrangling/Exploring_New_Data_with_Tidyverse.html#lying",
    "title": "Happiness in the Tidyverse",
    "section": "Lying",
    "text": "Lying\nRepeat the above analysis comparing how peoples’ happiness scores depend on their attitudes about lying. http://127.0.0.1:41855/graphics/e18505de-f3d7-47b3-b868-2c638e36eb4c.png\n\nCreate a new dataset called lying that excludes the #N/A values in Lying and the Happiness scores outliers, and includes only “Happiness_score” and “Lying”:\n\n\nsteve &lt;- happiness %&gt;%\n  filter(Happiness_score &lt;= 15, \n         Happiness_score &gt;= 0, \n         Lying != \"#N/A\"\n  ) %&gt;%\n  select(Happiness_score, Lying)\n\n#View(steve)\n\n\nCreate a side-by-side boxplot and summary statistics (using favstats()) table for each attitude about Lying:\n\n\nboxplot(steve$Happiness_score ~ steve$Lying)\n\n\n\n\n\n\n\nfavstats(steve$Happiness_score ~ steve$Lying)\n\n                    steve$Lying min Q1 median Q3 max     mean       sd   n\n1         everytime it suits me   5  9     10 11  15 10.05839 2.175284 137\n2                         never   4  9     11 12  15 10.80000 2.138090  50\n3 only to avoid hurting someone   3  9     11 12  15 10.54444 1.997179 270\n4                     sometimes   3 10     11 12  15 10.71639 1.764933 543\n  missing\n1       0\n2       0\n3       0\n4       0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BYU-Idaho Math 221: Introduction to Statistics in R",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nYou can navigate the lessons using the “Lessons” drop down. Each lesson will consist of background readings, example code, and an opportunity to practice.\nHomework assignments can be viewed and downloaded from the “Homework” tab.\nApplication Activities are designed to give you a more real-world experience dealing with data.\nThe section labeled “R Help” provides resources to help with R programming.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list.\n\nHere is a specific, suggested reading schedule:\n\nCourse Introduction, including R installation\nSummarizing Data - Shape and Center\nSummarizing Data - Measures of Spread\nProbability\nNormal Distribution\nDistribution of Sample Means\nProbability Calculations for Means\nIntroduction to Hypothesis Testing\nIntroduction to Confidence Intervals\nInference for a Mean\nInference for Dependent Samples\nInference for Independent Samples\nANOVA\nRegression\nDistribution of \\(\\hat{p}\\)\nInference for 1 Proportion\nInference for 2 Proportions\nChi Square Test for Independence"
  },
  {
    "objectID": "index.html#a-customizable-textbook",
    "href": "index.html#a-customizable-textbook",
    "title": "BYU-Idaho Math 221: Introduction to Statistics in R",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nYou can navigate the lessons using the “Lessons” drop down. Each lesson will consist of background readings, example code, and an opportunity to practice.\nHomework assignments can be viewed and downloaded from the “Homework” tab.\nApplication Activities are designed to give you a more real-world experience dealing with data.\nThe section labeled “R Help” provides resources to help with R programming.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list.\n\nHere is a specific, suggested reading schedule:\n\nCourse Introduction, including R installation\nSummarizing Data - Shape and Center\nSummarizing Data - Measures of Spread\nProbability\nNormal Distribution\nDistribution of Sample Means\nProbability Calculations for Means\nIntroduction to Hypothesis Testing\nIntroduction to Confidence Intervals\nInference for a Mean\nInference for Dependent Samples\nInference for Independent Samples\nANOVA\nRegression\nDistribution of \\(\\hat{p}\\)\nInference for 1 Proportion\nInference for 2 Proportions\nChi Square Test for Independence"
  },
  {
    "objectID": "index.html#book-scope",
    "href": "index.html#book-scope",
    "title": "BYU-Idaho Math 221: Introduction to Statistics in R",
    "section": "Book Scope",
    "text": "Book Scope\nThis is an introductory book intended to familiarize students with foundational concepts and vocabulary in statistics and introduce basic data wrangling and visualization in R.\nThose who diligently work through these materials should be well prepared for their next statistics course whether in Psychology or Fish and Wildlife Management."
  },
  {
    "objectID": "Textbook/Intro_to_Probability.html",
    "href": "Textbook/Intro_to_Probability.html",
    "title": "Intro to Probability",
    "section": "",
    "text": "Probability is a way of numerically quantifying how likely an event is to happen or not happen. The following historical account demonstrates this idea and shows how fractions (like 1/2 or 3/4) or percentages (like 50% or 75%) can be used to represent probabilities.\n\n\n\nOn August 3, 1492, Columbus set sail from Spain for his intended destination: the Indies (Caso, Adolph 1990). He was on the Santa Maria, which had a crew of approximately 41 men (“Cristobal colon” 1991; “Christopher Columbus”). Several other men were aboard the Nina and the Pinta (“Cristobal colon” 1991). On October 12, he landed on an island in the Bahamas he called San Salvador.\nThe return trip was not without challenges. The Santa Maria ran aground on Christmas Day, 1492, and was abandoned on the island we now call Hispaniola (home to Haiti and the Dominican Republic). Following this incident, Columbus sailed for Spain. Severe storms made the journey difficult. A particularly bad storm on February 14, 1493 made the crew fear for their lives. By morning, the storm was even worse!\nRecognizing his dependence upon God, Columbus ordered that a pilgrimage should be made to a particular shrine upon their safe arrival in Spain. He decided that they would use random chance to determine who would make the pilgrimage. They took one chick pea for each man on board. A knife was used to mark one of the chick peas with a cross. The chick peas were placed in a hat and shaken up. Each man was to draw a chick pea, and the one who had the cross would make the pilgrimage.\n“The first who put in his hand was [Columbus,] and he drew out the bean with a cross, so the lot fell on him; and he was bound to go on the pilgrimage and fulfil the vow” (Caso, Adolph 1990).\n\nAnswer the following questions:\n\n\n\nRemember, there were 41 men aboard his ship. What is the probability that Columbus would draw out the marked chick pea? Express your answer as a fraction, and then convert it to a decimal.\n\n\n\nShow/Hide Solution\n\nThere is only one marked chick pea in the hat, out of 41 chick peas total. Out of is expressed arithmetically by division. The probability is \\(\\frac{1}{41} = 0.0244\\). (Note: this is about 2%.)\n\n\nBased on your answer to the previous question, how likely is it that Columbus would draw out the marked chick pea?\n\n\n\nShow/Hide Solution\n\n\nThere is only about a 2% chance that Columbus will draw out the marked Chick Pea. This is not very likely.\n\n\n\n\nA Second Drawing\nColumbus’ promise to make the pilgrimage did not stop the storm. It was determined that there should be a pilgrimage to another site they held sacred. Again, chick peas representing each member of the crew were placed in a hat and shaken up. The lot fell on a sailor…named Pedro de Villa (Caso, Adolph 1990).\n\nAnswer the following questions:\n\n\n\nWhat is the probability that Columbus would not draw out the marked chick pea? Express your answer as a fraction, and then covert it to a decimal?\n\n\n\nShow/Hide Solution\n\n\nThere are 40 other men on board plus Columbus. So, the probability that Columbus would not draw out the marked chick pea is: \\(\\frac{40}{41} = 0.9756\\). (Note: this is almost 98%.)\n\n\n\nBased on your answer to the previous question, how likely is it that Columbus would not draw out the marked chick pea?\n\n\n\nShow/Hide Solution\n\n\nIt is very likely that Columbus would not draw out the marked chick pea. This result is not surprising.\n\n\n\nIn this second drawing, either Columbus would draw out the marked chick pea, or he would not. Add the probability that Columbus would draw out the marked chick pea and the probability that he would not draw out the marked chick pea. What is the value of this sum?\n\n\n\nShow/Hide Solution\n\n\nThe sum of the probabilities is 1:\n\n\\[\n\\frac{1}{41} + \\frac{40}{41} = \\frac{41}{41} = 1\n\\]\n\n\n\nAdditional Drawings\nAfter the drawing in which Pedro de Villa was chosen to make a pilgrimage, two additional drawings were held. In both cases, Columbus drew out the marked chick pea (Caso, Adolph 1990). In all, Christopher Columbus drew the marked chick pea in three of the four drawings. It can be shown that the probability that this would occur due to chance is very small: 0.0000566.\nBonus material. Read only if you are interested.\nThis calculation is more involved than the calculations you will be required to make in this course this semester. But if you are still interested, read on.\nIn each individual drawing, there was a 1/41 chance of Columbus getting the marked chick pea. Similarly, there was a 40/41 chance of not getting it. Since there were four drawings total, and the goal is to measure the probability of “three of those drawings” resulting in Columbus getting the marked chick pea, it becomes important to think about all of the orders in which Columbus could have gotten 3 out of 4.\n\n\n\n\n\n\n\n\n\n\nPossible Outcome\nFirst Drawing\nSecond Drawing\nThird Drawing\nFourth Drawing\n\n\n\n\nWhat actually happened…\nGot it.\nDidn’t get it.\nGot it.\nGot it.\n\n\nBut he could have…\nGot it.\nGot it.\nDidn’t get it.\nGot it.\n\n\nOr he could have…\nGot it.\nGot it.\nGot it.\nDidn’t get it.\n\n\nOr he could have…\nDidn’t get it.\nGot it.\nGot it.\nGot it.\n\n\n\nIn each of the above cases, notice that Columbus would have gotten the marked chick pea a total of 3 out of 4 times. So, this tells us there are four diffent ways to get the chick pea 3 out of 4 times.\nThe probability of what actually happened to Columbus in the order in which it happened would be computed by multiplying the individual probabilities of each drawing together.\n\\[\n  \\frac{1}{41} \\cdot \\frac{40}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\approx 0.00001415548\n\\]\nBut then, we must also add to this the other “possible” scenarios that would also lead to getting the chick pea 3 out of 4 times, but as shown below, because multiplication is commutative (the order doesn’t matter) these “different” situations result in the same probability as the first.\n\\[\n  \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{40}{41} \\cdot \\frac{1}{41} \\approx 0.00001415548\n\\]\n\\[\n  \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{40}{41} \\approx 0.00001415548\n\\]\n\\[\n  \\frac{40}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\approx 0.00001415548\n\\]\nThus, all that is needed is to multiply the first probability of roughly 0.00001415548 by 4 to get \\(0.00001415548 \\cdot 4 = 0.00005662192\\).\nEnd of Bonus Material."
  },
  {
    "objectID": "Textbook/Intro_to_Probability.html#probability",
    "href": "Textbook/Intro_to_Probability.html#probability",
    "title": "Intro to Probability",
    "section": "",
    "text": "Probability is a way of numerically quantifying how likely an event is to happen or not happen. The following historical account demonstrates this idea and shows how fractions (like 1/2 or 3/4) or percentages (like 50% or 75%) can be used to represent probabilities.\n\n\n\nOn August 3, 1492, Columbus set sail from Spain for his intended destination: the Indies (Caso, Adolph 1990). He was on the Santa Maria, which had a crew of approximately 41 men (“Cristobal colon” 1991; “Christopher Columbus”). Several other men were aboard the Nina and the Pinta (“Cristobal colon” 1991). On October 12, he landed on an island in the Bahamas he called San Salvador.\nThe return trip was not without challenges. The Santa Maria ran aground on Christmas Day, 1492, and was abandoned on the island we now call Hispaniola (home to Haiti and the Dominican Republic). Following this incident, Columbus sailed for Spain. Severe storms made the journey difficult. A particularly bad storm on February 14, 1493 made the crew fear for their lives. By morning, the storm was even worse!\nRecognizing his dependence upon God, Columbus ordered that a pilgrimage should be made to a particular shrine upon their safe arrival in Spain. He decided that they would use random chance to determine who would make the pilgrimage. They took one chick pea for each man on board. A knife was used to mark one of the chick peas with a cross. The chick peas were placed in a hat and shaken up. Each man was to draw a chick pea, and the one who had the cross would make the pilgrimage.\n“The first who put in his hand was [Columbus,] and he drew out the bean with a cross, so the lot fell on him; and he was bound to go on the pilgrimage and fulfil the vow” (Caso, Adolph 1990).\n\nAnswer the following questions:\n\n\n\nRemember, there were 41 men aboard his ship. What is the probability that Columbus would draw out the marked chick pea? Express your answer as a fraction, and then convert it to a decimal.\n\n\n\nShow/Hide Solution\n\nThere is only one marked chick pea in the hat, out of 41 chick peas total. Out of is expressed arithmetically by division. The probability is \\(\\frac{1}{41} = 0.0244\\). (Note: this is about 2%.)\n\n\nBased on your answer to the previous question, how likely is it that Columbus would draw out the marked chick pea?\n\n\n\nShow/Hide Solution\n\n\nThere is only about a 2% chance that Columbus will draw out the marked Chick Pea. This is not very likely.\n\n\n\n\nA Second Drawing\nColumbus’ promise to make the pilgrimage did not stop the storm. It was determined that there should be a pilgrimage to another site they held sacred. Again, chick peas representing each member of the crew were placed in a hat and shaken up. The lot fell on a sailor…named Pedro de Villa (Caso, Adolph 1990).\n\nAnswer the following questions:\n\n\n\nWhat is the probability that Columbus would not draw out the marked chick pea? Express your answer as a fraction, and then covert it to a decimal?\n\n\n\nShow/Hide Solution\n\n\nThere are 40 other men on board plus Columbus. So, the probability that Columbus would not draw out the marked chick pea is: \\(\\frac{40}{41} = 0.9756\\). (Note: this is almost 98%.)\n\n\n\nBased on your answer to the previous question, how likely is it that Columbus would not draw out the marked chick pea?\n\n\n\nShow/Hide Solution\n\n\nIt is very likely that Columbus would not draw out the marked chick pea. This result is not surprising.\n\n\n\nIn this second drawing, either Columbus would draw out the marked chick pea, or he would not. Add the probability that Columbus would draw out the marked chick pea and the probability that he would not draw out the marked chick pea. What is the value of this sum?\n\n\n\nShow/Hide Solution\n\n\nThe sum of the probabilities is 1:\n\n\\[\n\\frac{1}{41} + \\frac{40}{41} = \\frac{41}{41} = 1\n\\]\n\n\n\nAdditional Drawings\nAfter the drawing in which Pedro de Villa was chosen to make a pilgrimage, two additional drawings were held. In both cases, Columbus drew out the marked chick pea (Caso, Adolph 1990). In all, Christopher Columbus drew the marked chick pea in three of the four drawings. It can be shown that the probability that this would occur due to chance is very small: 0.0000566.\nBonus material. Read only if you are interested.\nThis calculation is more involved than the calculations you will be required to make in this course this semester. But if you are still interested, read on.\nIn each individual drawing, there was a 1/41 chance of Columbus getting the marked chick pea. Similarly, there was a 40/41 chance of not getting it. Since there were four drawings total, and the goal is to measure the probability of “three of those drawings” resulting in Columbus getting the marked chick pea, it becomes important to think about all of the orders in which Columbus could have gotten 3 out of 4.\n\n\n\n\n\n\n\n\n\n\nPossible Outcome\nFirst Drawing\nSecond Drawing\nThird Drawing\nFourth Drawing\n\n\n\n\nWhat actually happened…\nGot it.\nDidn’t get it.\nGot it.\nGot it.\n\n\nBut he could have…\nGot it.\nGot it.\nDidn’t get it.\nGot it.\n\n\nOr he could have…\nGot it.\nGot it.\nGot it.\nDidn’t get it.\n\n\nOr he could have…\nDidn’t get it.\nGot it.\nGot it.\nGot it.\n\n\n\nIn each of the above cases, notice that Columbus would have gotten the marked chick pea a total of 3 out of 4 times. So, this tells us there are four diffent ways to get the chick pea 3 out of 4 times.\nThe probability of what actually happened to Columbus in the order in which it happened would be computed by multiplying the individual probabilities of each drawing together.\n\\[\n  \\frac{1}{41} \\cdot \\frac{40}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\approx 0.00001415548\n\\]\nBut then, we must also add to this the other “possible” scenarios that would also lead to getting the chick pea 3 out of 4 times, but as shown below, because multiplication is commutative (the order doesn’t matter) these “different” situations result in the same probability as the first.\n\\[\n  \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{40}{41} \\cdot \\frac{1}{41} \\approx 0.00001415548\n\\]\n\\[\n  \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{40}{41} \\approx 0.00001415548\n\\]\n\\[\n  \\frac{40}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\cdot \\frac{1}{41} \\approx 0.00001415548\n\\]\nThus, all that is needed is to multiply the first probability of roughly 0.00001415548 by 4 to get \\(0.00001415548 \\cdot 4 = 0.00005662192\\).\nEnd of Bonus Material."
  },
  {
    "objectID": "Textbook/Intro_to_Probability.html#conclusion",
    "href": "Textbook/Intro_to_Probability.html#conclusion",
    "title": "Intro to Probability",
    "section": "Conclusion",
    "text": "Conclusion\nAs with all the classes you take at BYU-Idaho, it is up to you to decide what you want to get out of this class. If you choose to approach the things you study in class with an open mind, if you prepare diligently and work hard to complete all the learning activities, and if you humbly seek the Lord’s help to understand the intellectual and spiritual truths discussed in this course and in other courses, you will have an outstanding educational experience that will be a blessing to you throughout your life. May you enjoy the journey this semester into statistics!"
  },
  {
    "objectID": "Textbook/Intro_to_Probability.html#summary",
    "href": "Textbook/Intro_to_Probability.html#summary",
    "title": "Intro to Probability",
    "section": "Summary",
    "text": "Summary\n\nRemember…\n\n\n\nIn this class you will use the online textbook that has been written for you by your statistics teachers. All of the assignments and quizzes, available in I-Learn, will be based on the readings, so study it well. Most weeks will cover two lessons.\nYou have successfully located the online textbook. Ensure you have also located the course in I-Learn and can access the quizzes and assignments that are there.\nEnsure you have located the contact information for your instructor in the I-Learn course. Recording the contact information of peers from class would also be a wise idea.\nThis course uses MS Excel for all statistical analysis. Check that you have access to the software on your computer. If not, see I-Learn for details on how to obtain it through the University for free.\nBy doing the work, staying on schedule, and living the Honor Code you will succeed in this class.\nThe three rules of probability are:\n\nA probability is a number between 0 and 1. \\[0 \\leq P(X) \\leq 1\\]\nIf you list all the outcomes of a probability experiment (such as rolling a die) the probability that one of these outcomes will occur is 1. In other words, the sum of the probabilities in any probability is 1. \\[\\sum P(X) = 1\\]\nThe probability that an outcome will not occur is 1 minus the probability that it will occur. \\[P(\\text{not}~X) = 1 - P(X)\\]"
  },
  {
    "objectID": "Textbook/Spread.html",
    "href": "Textbook/Spread.html",
    "title": "Describing Quantitative Data (Spread)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nCalculate a percentile from data\nInterpret a percentile\nCalculate the standard deviation from data\nInterpret the standard deviation\nCalculate the five-number summary using software\nInterpret the five-number summary\nCreate a box plot using software\nDetermine the five-number summary visually from a box plot"
  },
  {
    "objectID": "Textbook/Spread.html#lesson-outcomes",
    "href": "Textbook/Spread.html#lesson-outcomes",
    "title": "Describing Quantitative Data (Spread)",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nCalculate a percentile from data\nInterpret a percentile\nCalculate the standard deviation from data\nInterpret the standard deviation\nCalculate the five-number summary using software\nInterpret the five-number summary\nCreate a box plot using software\nDetermine the five-number summary visually from a box plot"
  },
  {
    "objectID": "Textbook/Spread.html#spread-of-a-distribution",
    "href": "Textbook/Spread.html#spread-of-a-distribution",
    "title": "Describing Quantitative Data (Spread)",
    "section": "Spread of a Distribution",
    "text": "Spread of a Distribution\nIn the previous lesson, we introduced two important characteristics of a distribution: the shape and the center. In this section, you will discover ways to summarize the spread of a distribution of data. The spread of a distribution of data describes how far the observations tend to be from each other. There are many ways to describe the spread of a distribution, but one of the most popular measurements of spread is called the “standard deviation.” \n\nStandard Deviation and Variance\nThis activity introduces two measures of spread: the standard deviation and the variance.\n\nBird Flu Fever \n\nAvian Influenza A H5N1, commonly called the bird flu, is a deadly illness that is currently only passed to humans from infected birds. This illness is particularly dangerous because at some point it is likely to mutate to allow human-to-human transmission. Health officials worldwide are preparing for the possibility of a bird flu pandemic.\n\nDr. K. Y. Yuen led a team of researchers who reported the body temperatures of people admitted to Chinese hospitals with confirmed cases of Avian Influenza. Their research team collected data on the body temperature at the time that people with the bird flu were admitted to the hospital. In the article, they reported on two groups of people, those with relatively uncomplicated cases of the bird flu and those with severe cases.\n\nThe table below presents the data representative of the body temperatures for the two groups of bird flu patients:\n\n\n\nBody Temperature\nCase Type\n\n\n\n\n38.1\nSimple\n\n\n38.3\nSimple\n\n\n38.4\nSimple\n\n\n39.5\nSimple\n\n\n39.7\nSimple\n\n\n39.1\nSevere\n\n\n39.5\nSevere\n\n\n38.9\nSevere\n\n\n39.2\nSevere\n\n\n39.9\nSevere\n\n\n39.7\nSevere\n\n\n39.0\nSevere\n\n\n\n\nLet us focus on the relatively uncomplicated cases. Creating a histogram of such a small dataset does not provide much benefit. With only a handful of values, there is not much shape to the distribution.\nWe can, however, use numerical summaries to give an indication of the center of the distribution.\n\nAnswer the following questions:\n\n\n\nWhat is the median of the body temperatures for the simple cases? \n\n\n\nSolution\n\n\nThe median body temperature for the simple cases is 38.4 degrees Centigrade.\n\n\n\nWhat is the mean of the body temperatures for the simple cases? \n\n\n\nSolution\n\n\nThe mean body temperature for the simple cases is 38.8 degrees Centigrade.\n\n\n\n\nWe will use these data to investigate some measures of the spread in a data set.\nThere is relatively little difference in the temperatures of the uncomplicated patients. The lowest is \\(38.1 ^\\circ \\text{C}\\), while the highest temperature is \\(39.7 ^\\circ \\text{C}\\).\nThe standard deviation is a measure of the spread in the distribution. If the data tend to be close together, then the standard deviation is relatively small. If the data tend to be more spread out, then the standard deviation is relatively large.\nThe standard deviation of the body temperatures is \\(0.742 ^\\circ \\text{C}\\). This number contains information from all the patients. If the patients’ temperatures had been more diverse, the standard deviation would be larger. If the patients’ temperatures were more uniform (i.e. closer together), then the standard deviation would have been smaller. If all the patients somehow had the same temperature, then the standard deviation would be zero.\nWe are working with a sample. To be explicit, we call \\(0.742 ^\\circ \\text{C}\\) the sample standard deviation. The symbol for the sample standard deviation is \\(s\\). This is a statistic. The parameter representing the population standard deviation is \\(\\sigma\\) (pronounced /SIG-ma/). In practice, we rarely know the value of the population standard deviation, so we use the sample standard deviation \\(s\\) as an approximation for the unknown population standard deviation \\(\\sigma\\).\nAt this point, you probably do not have much intuition regarding the standard deviation. We will use this statistic frequently. By the end of the semester you can expect to become very comfortable with this idea. For now, all you need to know is that if two variables are measured on the same scale, the variable with values that are further apart will have the larger standard deviation.\n\nR Instructions\n\n\n  To calculate the sample standard deviation in R, follow these steps:   \n\ndata &lt;- c(38.1,38.3,38.4,39.5,39.7,39.1,39.5,38.9,39.2,39.9,39.7,39.0)\n\nsd(data)\n\n[1] 0.5930788\n\n\n\n\n\n\nRounding: As a general rule, when reporting your answers in this class, round to three decimal places unless otherwise specified.\n\n \n\nCalculating the Standard Deviation by Hand\nHow is the standard deviation computed? Where does this “magic” number come from? How does one number include the information about the spread of all the points?\nIt is a little tedious to compute the standard deviation by hand. You will usually compute standard deviation with a computer. However, the process is very instructive and will help you understand conceptually what the statistic represents. As you work through the following steps, please remember the goal is to find a measure of the spread in a data set. We want one number that describes how spread out the data are.\nFirst, observe the number line below, where each x represents the temperature of a patient with a relatively uncomplicated case of bird flu. As mentioned earlier, there is not a huge spread in the temperatures.\n\nOn your sketch of the number line, we draw a vertical line at 38.8 degrees, the sample mean. Now, draw horizontal lines from the mean to each of your \\(\\times\\)’s. These horizontal line segments represent the spread of the data about the mean. Your plot should look something like this:\n\nThe length of each of the line segments represents how far each observation is from the mean. If the data are close together, these lines will be fairly short. If the distribution has a large spread, the line segments will be longer. The standard deviation is a measure of how long these lines are, as a whole.\nThe distance between the mean and an observation is referred to as a deviation. In other words, deviations are the lengths of the line segments drawn in the image above.\n\\[\n\\begin{array}{1cl}\n\\text{Deviation} & = & \\text{Value} - \\text{Mean} \\\\\n\\text{Deviation} & = & x - \\bar x\n\\end{array}\n\\]\nIf the observed value is greater than the mean, the deviation is positive. If the value is less than the mean, the deviation is negative.\nThe standard deviation is a complicated sort of average of the deviations. Making a table like the one below will help you keep track of your calculations. Please participate fully in this exercise. Writing your answers at each step and developing a table as instructed will greatly enhance the learning experience. By following these steps, you will be able to compute the standard deviation by hand, and more importantly, understand what it is telling you.\nStep 01: The first step in computing the standard deviation by hand is to create a table, like the following. Enter the observed data in the first column.\n\n\n\n\n\n\nObservation (\\(x\\))\n\n\n\n\n\n\nDeviation from the Mean (\\(x-\\bar x\\))\n\n\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\n\n\n\n\\(39.5\\)\n\n\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\n\n\n\n\nStep 02: The second column of the table contains the deviations from the mean. Complete column 2 of the table above.\nCheck Results for Step 2\n\n\n\n\n\n\nObservation (\\(x\\))\n\n\n\n\nDeviation from the Mean (\\(x-\\bar x\\))\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\\(38.3-38.8=-0.5\\)\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\\(38.4-38.8=-0.4\\)\n\n\n\n\n\n\n\\(39.5\\)\n\n\n\n\n\\(39.5-38.8=0.7\\)\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\\(39.7-38.8=0.9\\)\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\n\n\n\n\n\n\nAnswer the following questions:\n\n\n\nHow could we use this table to find the “typical” distance from each point to the mean? Think carefully about this, and then write down your answer before continuing.\n\n\n\nSolution\n\n\nYou may have suggested that we compute the mean of these values. This seems like a good idea. If we compute the mean, it will tell us the average deviation from the mean. \n\n\n9b. Compute the mean of Column 2. What do you get?\n\n\nSolution\n\n\nYou should have found that the mean of the deviations is zero. This is true for every data set. If you add up the deviations from the mean, the positive values will cancel with the negative values. The sum of the deviations from the mean will be zero, so the mean also must equal zero.\nThe good news is that you can use this fact to check if you are on the right track. If the deviations from the mean do not add up to zero, then you have made a mistake in the calculations. The bad news is that the deviations always add up to 0, making it look like the distance from the data to the mean is 0. Nonsense!\nThe mean of the deviations from the mean cannot be used to find a measure of the spread in a data set, but it does provide a guidepost that shows we are on the right track. We must find another way to estimate the spread of a data set.\n\n\n\nWe need a way to work with the negative deviations from the mean, so they do not cancel with the positive ones. What could we do? (Choose one of the four options below.)\n\n\n\nOption 1: Take the absolute value of the deviations\n\n\nThis is an excellent suggestion. This is probably one of the first things statisticians used to estimate the spread in the data.\nIf we take the absolute value of the deviations, then all the values are positive. By taking the mean of these numbers, we do get a measure of spread. This quantity is called the mean absolute deviation (MAD).\nThere is good news and bad news. The good news is, you discovered a way to estimate the spread in a data set. (In fact, the MAD is used as one estimate of the volatility of stocks.) The bad news is that the MAD does not have good theoretical properties. A proof of this claim requires calculus, and so will not be discussed here. For most applications, there is a better choice. Please select another option.\n\n\n\n\nOption 2: Square the deviations\n\n\nIf we square the deviations from the mean, the values that were negative will become positive. This leads to an estimator of the spread that has excellent theoretical properties. This is the best of the four options. You will apply this idea in Step 03.\n\n\n\n\nOption 3: Delete the negative deviations\n\n\nSorry, you can’t make your troubles go away by deleting things you don’t like. Please try again.\n\n\n\n\nOption 4: Do something entirely different\n\n\nYou probably have an ingenious idea. Surprisingly enough, there is a right answer to the question. Please choose a different option.\n\n\n\nPlease do not go on to Step 03 until you have finished this exploration.\n\n\n\n\n“Piled Higher and Deeper” by Jorge Cham  \n\nStep 03: Add a third column to your table. To get the values in this column, square the deviations from the mean that you found in Column 2.\n\n\n\n\n\nObservation \\(x\\)\n\n\n\n\nDeviation from the Mean \\(x-\\bar x\\)\n\n\n\n\nSquared Deviation from the Mean \\(\\left(x-\\bar x\\right)^2\\)\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\\(38.3-38.8=-0.5\\)\n\n\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\\(38.4-38.8=-0.4\\)\n\n\n\n\n\n\n\n\n\\(39.5\\)\n\n\n\n\n\\(39.5-38.8=0.7\\)\n\n\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\\(39.7-38.8=0.9\\)\n\n\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\nSum \\(=0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation \\(x\\)\n\n\n\n\nDeviation from the Mean \\(x-\\bar x\\)\n\n\n\n\nSquared Deviation from the Mean \\(\\left(x-\\bar x\\right)^2\\)\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\\((-0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\\(38.3-38.8=-0.5\\)\n\n\n\n\n\\((-0.5)^2=0.25\\)\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\\(38.4-38.8=-0.4\\)\n\n\n\n\n\\((-0.4)^2=0.16\\)\n\n\n\n\n\n\n\\(9.5\\)\n\n\n\n\n\\(39.5-38.8=0.7\\)\n\n\n\n\n\\((0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\\(39.7-38.8=0.9\\)\n\n\n\n\n\\((0.9)^2=0.81\\)\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\nSum \\(=0\\)\n\n\n\n\n\n\n\n\nStep 04: Now, add up the squared deviations from the mean.\n\n\n\n\n\nObservation \\(x\\)\n\n\n\n\nDeviation from the Mean \\(x-\\bar x\\)\n\n\n\n\nSquared Deviation from the Mean \\(\\left(x-\\bar x\\right)^2\\)\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\\((-0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\\(38.3-38.8=-0.5\\)\n\n\n\n\n\\((-0.5)^2=0.25\\)\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\\(38.4-38.8=-0.4\\)\n\n\n\n\n\\((-0.4)^2=0.16\\)\n\n\n\n\n\n\n\\(39.5\\)\n\n\n\n\n\\(39.5-38.8=0.7\\)\n\n\n\n\n\\((0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\\(39.7-38.8=0.9\\)\n\n\n\n\n\\((0.9)^2=0.81\\)\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\nSum \\(=0\\)\n\n\n\n\nSum \\(=2.20\\)\n\n\n\n\n\nThe sum of the squared deviations is 2.20. \n\nAnswer the following questions:\n\n\n\nSuppose that the researchers had collected body temperature data on 500 bird flu patients instead of 5. What would happen to the sum of the squared deviations, if the distribution of the data is the same for the 500 patients as the 5 patients?\n\n\n\nSolution\n\n\nWe would expect the sum of the squared deviations to be a lot larger than it is now. We would be adding squared deviations for 500 observations instead of 5. So, the sum of the squared deviations would be about 100 times larger.\n\nRemember, we are trying to find a measure of the spread of a data set. Our final measure should not be dependent on the sample size. We need to do something else.\n\n\n\nPlease do not go on until you have finished this exercise.\n\n\n\nStep 05: Recall that an average is adding a bunch of things up and dividing by the number of things. Consider taking the average of the squared deviations by adding them up and dividing by the number of deviations.\nUnfortunately, this is what is technically known as a “biased” estimate. We don’t get into what that means in this class, but to correct for the bias, we divide by \\(n-1\\) instead.\nThe number you computed in Step 05 is called the sample variance. It is a measure of the spread in a data set. It has very nice theoretical properties. The variance plays an important role in Statistics. We denote the sample variance by the symbol \\(s^2\\).\nIt can be shown that the sample variance is an unbiased estimator of the true population variance (which is denoted \\(\\sigma^2\\).) This means that the sample variance can be considered a reasonable estimator of the population variance. If the sample size is large, this estimator tends to be very good.\n\n\nResults from Step 5\n\nThe sum of the squared deviations is the sum of the values in Column 3. This sum equals 2.20. We divide the sum of Column 3 (\\(2.20\\)) by \\(n-1=5-1=4\\) to get the sample variance, \\(s^2\\):\n\\[s^2=\\frac{sum}{n-1}=\\frac{2.20}{5-1}=0.55\\]\nThis is the sample variance.\n\n\n\n\n\nObservation \\(x\\)\n\n\n\n\nDeviation from the Mean \\(x-\\bar x\\)\n\n\n\n\nSquared Deviation from the Mean \\(\\left(x-\\bar x\\right)^2\\)\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\\((-0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\\(38.3-38.8=-0.5\\)\n\n\n\n\n\\((-0.5)^2=0.25\\)\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\\(38.4-38.8=-0.4\\)\n\n\n\n\n\\((-0.4)^2=0.16\\)\n\n\n\n\n\n\n\\(39.5\\)\n\n\n\n\n\\(39.5-38.8=0.7\\)\n\n\n\n\n\\((0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\\(39.7-38.8=0.9\\)\n\n\n\n\n\\((0.9)^2=0.81\\)\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\nSum \\(=0\\)\n\n\n\n\nSum \\(=2.20\\)\n\n\n\n\n\n\nVariance:\n\n\n\n\n\\(\\displaystyle{s^2=\\frac{sum}{n-1}=\\frac{2.20}{5-1}=0.55}\\)\n\n\n\n\n\n\n\n\n\n\nAnswer the following questions:\n\n\n\nThe temperature data for the bird flu patients are in degrees Centigrade. What are the units of the variance?\n\n\n\nSolution\n\n\nThe data in Column 1 of the table is in degrees Centigrade. The mean also is in degrees Centigrade.\nTo get the numbers in Column 2, we subtracted the mean from each of the values in Column 1.\nWe squared the values in Column 2 to get Column 3. The units for this column are degrees Centigrade squared.\n\nThe sum of the numbers in Column 3 will also be in units of degrees Centigrade squared.\nWhen we divided that sum by \\(n-1\\), we obtained the sample variance. The sample variance has units of degrees Centigrade squared. This is not easily interpretable. It would be much easier to think about it if our measure of spread was in the same units as the data.\n\n\n\nWhat operation can we do to the variance to get a quantity with units degrees Centigrade?\n\n\n\nSolution\n\n\nIf we take the square root of the variance, we get a quantity that has units of degrees Centigrade. This quantity is the standard deviation.\n\n\n\n\nStep 06: Take the square root of the sample variance to get the sample standard deviation.\nThe sample standard deviation is defined as the square root of the sample variance.\n\\[\\text{Sample Standard Deviation} = s = \\sqrt{ s^2 } = \\sqrt{\\strut\\text{Sample Variance}}\\]\nThe standard deviation has the same units as the original observations. We use the standard deviation heavily in statistics.\nThe sample standard deviation (\\(s\\)) is an estimate of the true population standard deviation (\\(\\sigma\\)).\n\nAnswer the following questions:\n\n\n\nWhat is the sample standard deviation, \\(s\\), of the temperatures of the five patients with relatively uncomplicated cases of the bird flu?\n\n\n\nSolution\n\n\nThe sum of the squared deviations is the sum of the values in Column 3. This sum equals 2.20. We divide the sum of Column 3 (\\(2.20\\)) by \\(n-1=5-1=4\\) to get the sample variance, \\(s^2\\):\n\n\n\\(s^2=\\frac{sum}{n-1}=\\frac{2.20}{5-1}=0.55\\)\n\n\nThis is the sample variance.\n\n\n\n\n\n\nObservation \\(x\\)\n\n\n\n\nDeviation from the Mean \\(x-\\bar x\\)\n\n\n\n\nSquared Deviation from the Mean \\(\\left(x-\\bar x\\right)^2\\)\n\n\n\n\n\n\n\n\n\\(38.1\\)\n\n\n\n\n\\(38.1-38.8=-0.7\\)\n\n\n\n\n\\((-0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(38.3\\)\n\n\n\n\n\\(38.3-38.8=-0.5\\)\n\n\n\n\n\\((-0.5)^2=0.25\\)\n\n\n\n\n\n\n\\(38.4\\)\n\n\n\n\n\\(38.4-38.8=-0.4\\)\n\n\n\n\n\\((-0.4)^2=0.16\\)\n\n\n\n\n\n\n\\(39.5\\)\n\n\n\n\n\\(39.5-38.8=0.7\\)\n\n\n\n\n\\((0.7)^2=0.49\\)\n\n\n\n\n\n\n\\(39.7\\)\n\n\n\n\n\\(39.7-38.8=0.9\\)\n\n\n\n\n\\((0.9)^2=0.81\\)\n\n\n\n\n\n\n\\(\\bar x = 38.8\\)\n\n\n\n\nSum \\(=0\\)\n\n\n\n\nSum \\(=2.20\\)\n\n\n\n\n\n\nVariance:\n\n\n\n\n\\(\\displaystyle{s^2=\\frac{sum}{n-1}=\\frac{2.20}{5-1}=0.55}\\)\n\n\n\n\n\n\n\n\nStandard Deviation:\n\n\n\n\n\\(\\displaystyle{s = \\sqrt{s^2}=\\sqrt{0.55} \\approx 0.742}\\)\n\n\n\n\n\n\n\n\nThe sample standard deviation is \\(s = 0.742\\) degrees Centigrade.\nTake a few minutes to verify that you can recreate this table on your own.\n\n\n\n\n\n\nSummary\n\n  Standard Deviation\n  The standard deviation is one number that describes the spread in a set of data. If the data points are close together the standard deviation will be smaller than if they are spread out.\n  At this point, it may be difficult to understand the meaning and usefulness of the standard deviation. For now, it is enough for you to recognize the following points:\n\nThe standard deviation is a measure of how spread out the data are.\nIf the standard deviation is large, then the data are very spread out.\nIf the standard deviation is zero, then all the values are the identical–there is no spread in the data.\nThe standard deviation cannot be negative. \n\n\nVariance\nThe variance is the square of the standard deviation. The sample variance is denoted by the symbol \\(s^2\\). You found the sample standard deviation for patient temperatures of uncomplicated cases of bird in the bird above is \\(s = 0.74162\\). So, the sample variance for this data set is \\(s^2 = 0.74162^2 = 0.550\\). Be aware, if you had squared the rounded value of \\(s^2 = 0.742\\) in the calculation, you would have gotten an answer of 0.551 instead. This would be considered incorrect! \n\nRounding: Use unrounded values in interim calculations. Rounding too early in the process can lead to wrong answers.\n\n \n\nR Instructions\n\n\n  To calculate the sample variance in R:   \n\ndata &lt;- c(38.1,38.3,38.4,39.5,39.7,39.1,39.5,38.9,39.2,39.9,39.7,39.0)\n\nvar(data)\n\n[1] 0.3517424\n\n\n\n\n\nThe standard deviation and variance are two commonly used measures of the spread in a data set. Why is there more than one measure of the spread? The standard deviation and the variance each have their own pros and cons.\nThe variance has excellent theoretical properties. It is an unbiased estimator of the true population variance. That means that if many, many samples of \\(n\\) observations were drawn, the variances computed for all the samples would be centered nicely around the true population variance, \\(\\sigma^2\\). Because of these benefits, the variance is regularly used in higher-level statistics applications. One drawback of the variance is that the units for the variance are the square of the units for the original data. In the bird flu example, the body temperatures were measured in degrees Centigrade. So, the variance will have units of degrees Centigrade squared \\((^\\circ \\text{C})^2\\). What does degrees Centigrade squared mean? How do you interpret this? It doesn’t make any sense. This is one of the major drawbacks of the sample variance.\nBecause we take the square root of the variance to get the standard deviation, the standard deviation is in the same units as the original data. This is a great advantage, and is one of the reasons that the standard deviation is commonly used to describe the spread of data.\n\nAnswer the following questions:\n\n\nEnter the patient temperature data for the severe cases of bird flu into R Then use R to calculate the numerical summaries you have learned so far. As a reminder, the temperatures of patients with a severe case of bird flu are:\n\n39.1, 39.5, 38.9, 39.2, 39.9, 39.7, 39\n\n\nWhat is the mean, median, standard deviation and variance of the sample?\n\n\n\nSolution\n\n\nbird_flu &lt;- c(39.1, 39.5, 38.9, 39.2, 39.9, 39.7, 39)\n\nmean(bird_flu)\n\n[1] 39.32857\n\nmedian(bird_flu)\n\n[1] 39.2\n\nsd(bird_flu)\n\n[1] 0.377334\n\nvar(bird_flu)\n\n[1] 0.142381\n\n\n\n\nFor the next two questions, consider the histograms below comparing weight (in kilograms) of men (top histogram) to elephant seals (bottom histogram).\n\n\nWeight of Men Compared to Weight of Seals \n\n\nBased on the histograms, who has a greater sample mean weight, men or elephant seals?\n\n\n\nSolution\n\n\nThe mean is a measure of the center of a distribution. The mean weight of the men is less than the mean weight of the seals. We can see this because the bulk of the data in the histogram for the men’s weight is to the left of the seals’. The center of the distribution of elephant seals is about 195 kg. The center of the distribution of men’s weight is located below 100 kg on the number line.\n\n\n\n\nBased on the histograms, do the weights of men or elephant seals have a larger sample standard deviation?\n\n\n\nSolution\n\n\nStandard deviation is a measure of spread. You will note that the weights of the seals are more spread out than the weights of the men. Therefore, we conclude that the sample standard deviation of elephant seal weights is larger than the sample standard deviation of men’s weights.\n\n\n \n\n\nReview of Parameters and Statistics\nWe have now learned some statistics that can be used to estimate population parameters. For example, we use \\(\\bar x\\) to estimate the population mean \\(\\mu\\). The sample statistics \\(s\\) estimates the true population standard deviation \\(\\sigma\\). The following table summarizes what we have done so far:\n\n\n\n\n\n\n\n\nSample Statistic\n\n\n\n\nPopulation Parameter\n\n\n\n\n\n\n\n\nMean\n\n\n\n\n\\(\\bar x\\)\n\n\n\n\n\\(\\mu\\)\n\n\n\n\n\n\nStandard Deviation\n\n\n\n\n\\(s\\)\n\n\n\n\n\\(\\sigma\\)\n\n\n\n\n\n\nVariance\n\n\n\n\n\\(s^2\\)\n\n\n\n\n\\(\\sigma^2\\)\n\n\n\n\n\n\n\\(\\vdots\\)\n\n\n\n\n\\(\\vdots\\)\n\n\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\nUnless otherwise specified, we will always use Rto find the sample variance and sample mean. In each case, the sample statistic estimates the population parameter. The ellipses \\(\\vdots\\) in this table hint that we will add rows in the future.\n\nOptional Reading: Formulas for \\(s\\) and \\(s^2\\) (Hidden)\n\n\nClick here if you love math\n\nFormulas\nFor those who like formulas, the equation for the sample variance and sample standard deviation are given here.\nSample variance:\n\\[\\displaystyle{ s^2=\\frac{\\sum\\limits_{i=1}^n (x_i-\\bar x)^2}{n-1} }\\]\nSample standard deviation:\n\\[\\displaystyle{ s=\\sqrt{s^2}=\\sqrt{\\frac{\\sum\\limits_{i=1}^n (x_i-\\bar x)^2}{n-1}} }\\]\nwhere \\(x_i\\) is the \\(i^{th}\\) observed data value, and \\(i=1, 2, \\ldots, n\\).\nUnless otherwise specified, we will always use Excel to find the sample variance and sample mean.\nWhy do we divide by \\(n-1\\)?\nWhen computing the standard deviation or the variance, we are finding a value that describes the spread of data values. It is a measure of how far the data are from the mean. Since we do not know the true mean (\\(\\mu\\),) we use the sample mean (\\(\\bar x\\),) to estimate it. Typically, the data will be closer to \\(\\bar x\\) than to \\(\\mu\\), since \\(\\bar x\\) was computed using the data. To compensate for this, we divide by \\(n-1\\) rather than \\(n\\) when we find the “average” of the squared deviations from the mean. It turns out, that subtracting 1 from \\(n\\) inflates this average by the precise amount needed to compensate for the use of \\(\\bar x\\) as an estimate for \\(\\mu\\). As a result, the sample variance (\\(s^2\\)) is a good estimator of the population variance (\\(\\sigma^2\\).)\n\n\nNeither the standard deviation nor the variance is resistant to outliers. This means that when there are outliers in the data set, the standard deviation and the variance become artificially large. It is worth noting that the mean is also not resistant. When there are outliers, the mean will be “pulled” in the direction of the outliers.\nThe mean and standard deviation are used to describe the center and spread when the distribution of the data is symmetric and bell-shaped. If data are not symmetric and bell-shaped, we typically use the five-number summary (discussed below) to describe the spread, because this summary is resistant."
  },
  {
    "objectID": "Textbook/Spread.html#additional-tools-to-describe-the-data",
    "href": "Textbook/Spread.html#additional-tools-to-describe-the-data",
    "title": "Describing Quantitative Data (Spread)",
    "section": "Additional Tools to Describe the Data",
    "text": "Additional Tools to Describe the Data\nRecall the five steps of the Statistical Process (and the mnemonic “Daniel Can Discern More Truth).\n\n\n\n\n\n\nStep 1:\n\n\n\n\nDaniel\n\n\n\n\nDesign the study\n\n\n\n\n\n\nStep 2:\n\n\n\n\nCan\n\n\n\n\nCollect data\n\n\n\n\n\n\nStep 3:\n\n\n\n\nDiscern\n\n\n\n\nDescribe the data\n\n\n\n\n\n\nStep 4:\n\n\n\n\nMore\n\n\n\n\nMake inferences\n\n\n\n\n\n\nStep 5:\n\n\n\n\nTruth\n\n\n\n\nTake action\n\n\n\n\n\n\n\nStep 3 of this process is “Describe the data.” You have already learned about the mean, median, mode, standard deviation, variance and histograms. These can be good ways to describe the data. The following information on percentiles, quartiles, 5-number summaries, and boxplots will help you learn other common ways to describe data, especially if the data are skewed or contain outliers.\n\nFor symmetric, bell-shaped data, the mean and standard deviation provide a good description of the center and shape of the distribution. The mean and standard deviation are not sufficient to describe a distribution that is skewed or has outliers. An outlier is any observation that is very far from the others. The mean is pulled in the direction of the outlier. Also, the standard deviation is inflated by points that are very far from the mean.\nNow, you have probably had some experience with percentiles in the past especially when you received a score on a standardized test such as the ACT. Even though percentiles are commonly used, they are generally misunderstood. Before examining the wrong site/wrong patient data, let’s review percentiles. Even if you think you understand percentiles, please study this section carefully.\n\n\nPercentiles and Quartiles\nImagine a very long street with houses on one side. The houses increase in value from left to right. At the left end of the street is a small cardboard box with a leaky roof. Next door is a slightly larger cardboard box that does not leak. The houses eventually get larger and more valuable. The rightmost house on the street is a huge mansion.\n\nAnswer the following question:\n\n\n\nThere are 100 homes with increasing property values. How many fences are needed to separate the 100 properties?\n\n\n\nSolution\n\n\nIn order to separate the 100 homes, 99 fences are required.\n\n\n\n\nThe home values are representative of data. If we have a list of data, sorted in increasing order, and we want to divide it into 100 equal groups, we only need 99 dividers (like fences) to divide up the data. The first divider is as large or larger than 1% of the data. The second divider is as large or larger than 2% of the data, and so on. The last divider, the 99th, is the value that is as large or larger than 99% of the data. These dividers are called percentiles. A percentile is a number such that a specified percentage of the data are at or below this number. For example, the 99th percentile is a number such that 99% of the data are at or below this value. As another example, half (50%) of the data lie at or below the 50th percentile. The word percent means \\(\\div 100\\). This can help you remember that the percentiles divide the data into 100 equal groups.\nQuartiles are special percentiles. The word quartile is from the Latin quartus, which means “fourth.” The quartiles divide the data into four equal groups. The quartiles correspond to specific percentiles. The first quartile, Q1, is the 25th percentile. The second quartile, Q2, is the same as the 50th percentile or the median. The third quartile, Q3, is equivalent to the 75th percentile.\n\nAnswer the following questions:\n\n\n\nHow many quartiles are there?\n\n\n\nSolution\n\n\nThere are 3 quartiles! To divide the data into 100 equal groups, we needed 99 percentiles. To divide the data into 4 equal groups, we need 3 quartiles.\n\n \n\n\n\nWrong Site/Wrong Patient Lawsuits\nPercentiles can be used to describe the center and spread of any distribution and are particularly useful when the distribution is skewed or has outliers. To explore this issue, you will use software to calculate percentiles of data on costs incurred by hospitals due to certain lawsuits. The lawsuits in question were about surgeries performed on the wrong patient, or on the right patient but the wrong part of the patient’s body (the wrong site).\nBut first, we need to learn how to load data into R.\nR has many built-in toolboxes. R also has a vast array of toolboxes beyond the built-in ones that we must first install. This is like going to the Home Depot to buy a specialized toolbox and then storing it in your garage. We only have to “buy” it once.\nTo install a library, we use the install.packages(\"\") command, where we specify the library we want in the quotes inside the parentheses.\nrio is a toolbox that is very useful for loading data into R. If you haven’t already done so, install the rio library.\ninstall.packages('rio')\nWhile you only have to install libraries once, you have to load them every time you want to use one. It’s like going to the garage to get the toolbox you need for the job.\nNow let’s load the data and calculate some percentiles!\n\nR Instructions\n\n\n\nOpen R and load the rio library:\n\n\nlibrary(rio)\n\n\nUse the import() function to load the dataset:\n\n\nwrong_site &lt;- import(\"https://github.com/byuistats/Math221D_Course/raw/main/Data/WrongSiteWrongPatient.xlsx\")\n\n  To calculate percentiles and quartiles in R, do the following\n\nDatasets loaded into R may have many columns of information. To specify which column in the dataset should be used for analysis we use the $. For example, if we wanted only to look at the Wrong_Patient clumn in the wrong_site dataset:\n\n\n\n  [1]  250000  106900   62307  192800   20769    2680    4300   30819   23214\n [10]   26099       0   50000   66600  175000   10384   42900   52928       0\n [19]    8200    2500    6900  126300     900    7700  140000   76000   50000\n [28]  354530    5359    4300   12000   16749   35600    9045   21900    2010\n [37]   22444   50000   85000   40370   39863       0   36100   49000   48908\n [46]   19800   32200    3400       0   75000   21774    2600   30000    7300\n [55]  176940   55000    9500   55272    4690   75000   34168   83700    1005\n [64]   17419   34800   14739       0       0    1000     325   41538  108200\n [73]   63224   15000       0    3900   65657   50000  109205    3900   10000\n [82]    9900   87096   12090       0    1000       0   74701    3900   18000\n [91]       0   33499    1250       0   29813   11724  141363    3685   35508\n[100]    2500   12060    5695   50582   82071   55400       0  104400     500\n[109]       0   25000   10000   85000   25000       0   24100    3900 1250000\n[118]   15074     550    7195  101800   11600    1000    4020   19764   25794\n[127]     900   10000   35200   94100       0   16909  128400   60967   50000\n[136]   50000   84751   46800  130308   43800   49242   22800   15500   11054\n[145]     400   10000  104790   13064    6400  100000   17084   16300   11000\n[154]   12500       0    1200       0  200000    3900    3015  172200   25000\n[163]   27468  250000   21104   12500   30000   59000   46227     500  131000\n[172]    2345    6000       0     670    9714      NA      NA      NA      NA\n[181]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[190]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[199]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[208]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[217]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[226]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[235]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[244]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[253]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[262]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[271]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[280]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[289]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[298]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[307]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[316]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[325]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[334]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[343]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[352]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[361]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[370]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[379]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[388]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[397]      NA      NA      NA      NA      NA      NA      NA      NA      NA\n[406]      NA      NA      NA      NA      NA      NA\n\n\n\nUse R’s quantile() function. This functions requires two inputs separated by a comma: the data and the desired percentile input as a decimal.\nTo calculate the 25th percentile for the costs of surgery done on the Wrong Site:\n\n\nquantile(wrong_site$Wrong_Site, .25, na.rm=TRUE)\n\n  25% \n29496 \n\n# Note: the na.rm=TRUE removes the missing values from the dataset\n\n\n\n\nThe first quartile (\\(Q_1\\)) or 25th percentile (calculated in R) of the wrong-site data is: $29,496. (This result is illustrated in the figure below.) This means that 25 percent of the time hospitals lost a wrong-site lawsuit, they had to pay $29,496 or less. The 25th percentile can be written symbolically as: P25 = $29,496. Other percentiles can be written the same way. The 99th percentile can be written as P99.\n\nPercentiles (Calculated in Excel)\n\n\n\n\n \n \n\n\n\n\n1st percentile\n0\n\n\n2nd percentile\n0\n\n\n3rd percentile\n0\n\n\n…\n…\n\n\n24th percentile\n28633.4\n\n\n25th percentile\n29496\n\n\n26th percentile\n31067\n\n\n\n\n\nAnswer the following questions:\n\n\n\nWhat is the 13th percentile of the wrong site data?\n\n\n\nSolution\n\n\n$6343.40\n\n\nquantile(wrong_site$Wrong_Site, .13, na.rm=TRUE)\n\n   13% \n6343.4 \n\n\n\n\nHow would you interpret the 13th percentile (assuming the 13th percentile is $6343.40)?\n\n\n\n100 of the lawsuits cost more than 13%.\n\n\n13% of the lawsuits cost the hospital over $6343.40.\n\n\nIn 13% of the wrong-site lawsuits, hospitals had to pay $6343.40 or less.\n\n\nFor 13% of the wrong-site lawsuits, the hospitals had to pay $6343.40 to the patient.\n\n\n\n\nSolution\n\n\nCorrect Answer: C\n\n\n\n\nFind P90.\n\n\n\nSolution\n\n\n$149,963.00\n\n\nquantile(wrong_site$Wrong_Site, .9, na.rm=TRUE)\n\n   90% \n149963 \n\n\n\n\n\nThe quartiles divide a sorted list of data into four equal groups. So, each group contains 25% of the data. The first quartile is the value that is greater than or equal to 25% of the data. What is another name for this number?\n\n\n\nSolution\n\n\nThe 25th percentile.\n\n\n\n\nWhat is the value of the third quartile?\n\n\n\nSolution\n\n\n$124,280.00\n\n\nquantile(wrong_site$Wrong_Site, .75, na.rm=TRUE)\n\n   75% \n124280 \n\n\n\n\n\nHalf of the wrong-site lawsuits judgments were less than or equal to what value?\n\n\n\nSolution\n\n\n$68,552.00\n\n\nquantile(wrong_site$Wrong_Site, .5, na.rm=TRUE)\n\n  50% \n68552 \n\n#Or\nmedian(wrong_site$Wrong_Site)\n\n[1] 68552\n\n\n\n\n\nThe median is the middle observation in a sorted list of data. What percentile is always equal to the median?\n\n\n\nSolution\n\n\nThe 50th percentile\n\n\n \n\n\n\nThe Five-Number Summary\nAnother way to summarize data is with the five-number summary. The five-number summary is comprised of the minimum, the first quartile, the second quartile (or median), the third quartile, and the maximum.\nThere is a very easy way to get the Five-Number Summary along with the mean and standard deviation. The favstats() function in the mosaic library gives us all of our favorite statistics.\nAs before, we will have to install the mosaic library once, then load it when we want to use it.\n\nR Instructions\n\n\n  To find the values for a five-number summary in R, do the following\n\nInstall the mosaic library (Only Once):\n\ninstall.packages(\"mosaic\")\n\nLoad the Library:\n\n\nlibrary(mosaic)\n\n\nInput the data into the favstats() function:\n\n\nfavstats(wrong_site$Wrong_Site)\n\n min    Q1 median     Q3    max     mean       sd   n missing\n   0 29496  68552 124280 780575 80041.24 71403.83 411       0\n\n\n\n\n\n\nAnswer the following questions:\n\n\n\nGive the five-number summary for the Wrong Site data.\n\n\nSolution\n\n\n\\[\\displaystyle{\\$0,~~\\$29,496;~~\\$68,552;~~\\$124,280;~~\\$780,575}\\]\n\n\n \n\n\n\n\n\nSome students mistakenly include the mean in the five-number summary. The third value in the five-number summary is the median.\n\n \n\n\nBoxplots\nA boxplot is a graphical representation of the five-number summary. Unlike the mean or standard deviation, a boxplot is resistant to outliers. That means that it won’t be “pulled” one way or the other by extraordinarily large or small values in the data as will a mean, for instance. We will illustrate the process of making a boxplot using the wrong-site data.\nFollow the steps below to learn how a boxplot relates to the five-number summary. Learning what each part of the boxplot represents will enable you to interpret the plot correctly.\nStep 01: To draw a boxplot, start with a number line.\n\nStep 02: Draw a vertical line segment above each of the quartiles.\n\nStep 03: Connect the tops and bottoms of the line segments, making a box.\n\nStep 04: Make a smaller mark above the values corresponding to the minimum and the maximum.\n\nStep 05: Draw a line from the left side of the box to the minimum, and draw another line from the right side of the box the maximum.\n\nStep 06: These last two lines look like whiskers, so this is sometimes called a box-and-whisker plot.\n\n\n\nR Instructions\n\n\nTo create a boxplot in Excel, do the following\n\nLoad the data file. For this example, open the file WrongSiteWrongPatient.xlsx.\n\n\nwrong_site &lt;-  import(\"https://github.com/byuistats/Math221D_Course/raw/main/Data/WrongSiteWrongPatient.xlsx\")\n\n\nUse the boxplot() function to get a boxplot:\n\n\nboxplot(wrong_site$Wrong_Site)\n\n\n\n\n\n\n\n# We can make it a little nicer by adding labels to the x and y axes and adding a title as follows:\n\nboxplot(wrong_site$Wrong_Site, xlab=\"Wrong Site\", ylab=\"Cost in $\", main=\"Boxplot of Costs of Operating on the Wrong Site\")\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer the following questions:\n\n\n\nCreate a histogram of the wrong-patient lawsuit data, located in column B of the file WrongSiteWrongPatient.xlsx. What is the shape of the wrong-patient data?\n\n\nSkewed left\nSymmetric\nSkewed right\nMulti-modal\nUniform\n\n\n\nSolution\n\nTo create the histogram, use the histogram() function on the data:\n\nhistogram(wrong_site$Wrong_Patient)\n\n\n\n\n\n\n\n\nFrom the histogram we clearly see most values bunched near the left and gradually fewer values as we move to the right along the number line, so the correct answer is ‘c. Skewed right’."
  },
  {
    "objectID": "Textbook/Spread.html#summary-1",
    "href": "Textbook/Spread.html#summary-1",
    "title": "Describing Quantitative Data (Spread)",
    "section": "Summary",
    "text": "Summary\n\nRemember…\n\n\n\nA percentile is calculated in R using quantile(data, 0.#) where the 0.# is the percentile written as a decimal number. So the 20th percentile would be written as 0.2.\nA percentile is a number such that a specified percentage of the data are at or below this number. For example, if say 80% of college students were shorter than (or equal to) 70 inches tall in height, then the 80th percentile of heights of college students would be 70 inches.\nStandard deviation is calculated in R for a sample of data using sd(data).\nThe standard deviation is a number that describes how spread out the data typically are from the mean of that data. A larger standard deviation means the data are more spread out from their mean than data with a smaller standard deviation. The standard deviation is never negative. A standard deviation of zero implies all values in the data set are exactly the same.\nTo compute any of the five-number summary values in R, use the R function favstats(data) which also includes the mean and standard deviation.\nThe five-number summary consists of (1) the minimum value in the data, (2) the first quartile (25th percentile) of the data, (3) the median of the data (50th percentile), (4) the third quartile (75th percentile) of the data, and (5) the maximum value occurring in the data.\nTo create a boxplot in R, use the boxplot(data) or for multiple columns boxplot(data1, data2, names=c(\"Name of Column 1\", \"Name of Column 2)).\nBoxplots are a visualization of the five-number summary of a data set."
  },
  {
    "objectID": "Textbook/Spread.html#navigation",
    "href": "Textbook/Spread.html#navigation",
    "title": "Describing Quantitative Data (Spread)",
    "section": "Navigation",
    "text": "Navigation\n\n\n\nPrevious Reading\nThis Reading\nNext Reading\n\n\n\n\nLesson 3:  Describing Quantitative Data (Shape and Center)\nLesson 4:  Describing Quantitative Data (Spread)\nLesson 5:  Normal Distributions"
  }
]