---
title: "Distribution of Sample Statistics"
subtitle: "Class Exercise"
format:
  html:
    self-contained: true
    embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = TRUE)
```

# Introduction

This in-class activity will explore the distribution of sample statistics and the Central Limit Theorem.  

To demonstrate, we will be exploring a dataset about different species of penguins collected on different islands.  Background about the study and data can be found [here](https://www.kaggle.com/datasets/larsen0966/penguins/data).


Practice the process for approaching a dataset outlined in [class](https://byuistats.github.io/Math221D_Course/2-Tidy_Data/05-Exploring_New_Data_with_Tidyverse.html):

  1. Load the data and libraries
  2. Explore the data and generate hypotheses
  3. Prepare the data for analysis
  4. Perform the appropriate analysis
  
Data preparation will include using the `filter()` function.  For now, analysis means creating good visualizations that tell a story using `ggplot()` and base R.  

# 1 - Load the Data and Libraries


```{r}
library(tidyverse)
library(car)
library(mosaic)
library(rio)


penguins <- read_csv('https://github.com/byuistats/Math221D_Course/raw/refs/heads/main/Data/penguins.csv') %>% sample(30)

```



# 2 - Explore the data and generate hypotheses

Take time to explore the dataset including drilling down into individual columns.  

Recall a few useful functions for data exploration:

1. `names()` to get a list of the column names
2. `dim()` to get the number of rows and columns in a dataset
3. `table()` for getting counts of categorical data
4. `unique()` for getting a list of each of the distinct values of categorical data
5. `barchart()` or `ggplot()` to get a barchart for a categorical variable
6. `favstats()` to get summary statistics for quantitative data
7. `histogram()` to visualize the distribution of a single quantitative variable
8. `boxplot()` and/or `ggplot()` to compare the distributions of a quantitative variable for different groups


## Explore the data on your own

```{r}


```


__QUESTION__:  What is/are some potential dependent/response variables?  
__ANSWER__:  

__QUESTION__:  What are some potential explanatory variables?  
__ANSWER__:  


Let's look deeper into `bill_depth_mm`.  

# Bill Depth

## Create a table of summary statistics (`favstats()`) for bill_depth_mm:  

```{r}


```

__QUESTION__:  What is your sample mean?  
__ANSWER__:  


__QUESTION__:  What is your sample standard deviation?  
__ANSWER__: 


__QUESTION__:  What is your sample median?  
__ANSWER__: 


## Create a frequency table of `sex` (`table()`):

```{r}


```

__QUESTION__:  How many females in your sample?  
__ANSWER__:  

__QUESTION__:  How many males in your sample?  
__ANSWER__:  


## Create a table of `species`

```{r}

```

__QUESTION__:  How many Adelie penguins do you have in your sample?  
__ANSWER__:  

__QUESTION__:  How many Chinstrap penguins do you have in your sample?  
__ANSWER__:  

__QUESTION__:  How many Gentoo penguins do you have in your sample?  
__ANSWER__:  


## Create a side-by-side boxplot of bill_depth_mm for all species:  

```{r}


```


## Create a side-by-side boxplot of bill_depth_mm for all sex:  

```{r}


```



# Capture the means

Notice that we all have different samples and so we have different sample statistics!  

Click on [this link](https://docs.google.com/spreadsheets/d/1fYOYQfz4DTJyrn5UVIVes6bHD1J0DfcenwqqY9aMIRs/edit?usp=sharing) to add your sample statistics for __bill_depth_mm__ to the Google Sheet.  

```{r}



```



Notice in the above simulation of the Penguin data, for a given sample statistic (mean, median, standard deviation), the average was very close to the population parameter.  

The mean of our sample standard deviations was close to the *Population Standard Deviation*.  The mean of our sample medians was very close to the *Population Median*!

# Central Limit Theorem

Every time we take a sample, we will get different results.  

Today in class, we ran several independent experiments where each of us sampled 30 data points from a population.  The histogram of all of our sample means looks pretty "normal" even though we only ran a few dozen independent samples.  Our experiments were only a few of *all possible* samples.  

The __CLT__ states that the distribution of sample means is approximately normal with mean, $\mu_{\bar{x}}$, equal to the **Population Mean**, $\mu$, and standard deviation, $\sigma_{\bar{x}}$, equal to the population standard deviation divided by the square root of the sample size:  $\frac{\sigma}{\sqrt{n}}$.

The CLT holds even if the population is skewed!  Sample means can still be normally distributed.  


This means that under certain conditions, we can use the Normal Distribution to make calculations for **sample means**.


# Conclusion


While there are interesting properties of the distribution of **ANY** Sample Statistic, in this class we are mostly interested in the distribution of sample means.  

Because of the CLT, we can be confident about the mean, standard deviation, and the shape of the distribution of sample means.  

The fact that the distribution of sample means is normally distributed is foundational in the statistical tests that we will learn in the remainder of the course.  





# Bonus

If you're interested, you can run the following simulation changing sample sizes and the number of times you run the simulation and see how close you can get the mean of your sample statistics to the true population parameter.


I created a simulation that will sample a given sample size from the population for a specified number of simulations.



```{r}
# Create a function for running B simulations of a given sample size, N.    

favstats_simulation <- function(n_samples=500, sample_size=30){
  # Read in the entire population dataset:  
  penguins_population <- read_csv('https://github.com/byuistats/Math221D_Course/raw/refs/heads/main/Data/penguins.csv') 
  
  # Calculate the Population Parameters:  
  pop_params <- favstats(penguins_population$bill_depth_mm)
  parms <- tibble(pop_params) %>%
      select(mean, median, sd) %>%
      pivot_longer(cols = c(mean, median, sd), names_to = "Summary_Statistic", values_to = "Value") 
  
  favs <- NULL

  for(i in 1:n_samples){
    penguins_samp <- penguins_population %>% sample(sample_size)
    favs <- tibble(rbind(favs,favstats(penguins_samp$bill_depth_mm)))
  }

    long_dat <- favs %>%
      select(mean, median, sd) %>%
      pivot_longer(cols = c(mean, median, sd), names_to = "Summary_Statistic", values_to = "Value") 
    
  p <- ggplot(long_dat, aes(x=Value)) 
  p +
    geom_histogram(bins=20, fill="gray") +
    geom_vline(data = parms, aes(xintercept = Value), color="red", linetype=2) + 
    facet_grid(~Summary_Statistic, scales="free") +
    theme_bw()
    
  results <- rbind(pop_params,apply(favs, 2, mean)); row.names(results) <- c("Population Parameter", "Mean of Sample Stat")
  return(results[,c("median", "mean", "sd")])
  
}
```


```{r}

# See how close you can get the means of the sample statistics to the actual population parameters:


favstats_simulation(n_samples=50, sample_size = 30)
favstats_simulation(n_samples=1000, sample_size = 30)


# Try a bigger sample size:  
favstats_simulation(n_samples=1000, sample_size = 100)




```
