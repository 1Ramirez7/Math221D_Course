---
title: "Introducing Hypothesis Tests"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = TRUE)
```


# Introduction

In this lesson, we explore the components of statistical hypothesis testing in a general way.  These general principles will apply to all of the specific tests we will learn about during the rest of the semester.  

Lesson Objectives:  

  1. Understand what the null hypothesis, $H_0$, is and why we use it  
  2. Understand what the alternative hypothesis, $H_a$, is  
  3. Understand the concept of a test statistic as a "signal-to-noise" ratio  
    * Understand what is meant by "signal"  
    * Understand what is meant by "noise"  
  4. Understand the concept of a p-value  
  
  
# Hypothesis Testing

Hypothesis testing is a fundamental concept in statistics that allows us to make inferences about population parameters based on sample data. It's a structured method for using data to decide between two competing claims about a population.  

## The Null Hypothesis, $H_0$

The **null hypothesis** is the initial claim or assumption about a population parameter.  It often represents the status quo or "no effect".  

For example, we assume that the new medication has *no effect* until we find enough evidence to prove otherwise.  

We write the null hypothesis as, $H_0$, and refer to it as "H-Naught" or "H-O".  


Many of the statistical tests we cover in this course follow the generic form:  

$$H_0: \text{There is no relationship between }X \text{ and }Y$$
## The Alternative Hypothesis, $H_a$

We typically engage in scientific inquiry because we do NOT believe the null hypothesis.  For example, we believe that there IS an effect of a new medication.  

The "burden of proof" is on the researcher to prove the null hypothesis wrong.  This means that it is the researcher's responsibility to present enough evidence to contradict the null hypothesis.  

The counter-proposal for the null hypothesis is called the **alternative hypothesis**.  

We write the null hypothesis as, $H_a$, and refer to it as "H-A".  
The statistical tests we will cover in the rest of the semester follow the generic form:  

$$H_a: \text{There is a relationship between }X \text{ and }Y$$

## Visualizing the Null Hypothesis  

We always begin a study under the assumption that the null hypothesis is true.  

What would a true null hypothesis look like?  As we've explored data using descriptive statistics, we've seen many examples where there is no relationship between x and y.  

For example, if there was no relationship between `Height` and `Extroversion`, we would expect to see something like:


![](https://github.com/byuistats/Math221D_Course/raw/main/Images/No_Relationship_Scatterplot.png)
Because of sample-to-sample variability, the points wouldn't look exactly like this every time, but it would generally look like random scatter.  

If the null hypothesis is true, it would be very unlikely, though possible, to observe a scatter plot like the following, just by chance, because of sample-to-sample variation:  

![](https://github.com/byuistats/Math221D_Course/raw/main/Images/Some_Relationship_Scatterplot.png)

If the null hypothesis is true, it would be ASTRONOMICALLY unlikely, though theoretically possible, to observe a relationship like the following just by chance because of sample-to-sample variation:  

![](https://github.com/byuistats/Math221D_Course/raw/main/Images/Strong_Relationship_Scatterplot.png)



# Visualizing Ho for Group Means

Now consider the situation where you have a categorical explanatory variable and a continuous response variable.  Under the null hypothesis that there is no relationship between X and Y, the boxes in a boxplot should all line up to look roughly the same.  

Because of sample-to-sample variability, the boxes won't look identical.  

Below is an app that simulates data under the null hypothesis.  Any observed differences between boxes is part of the expected variation if there really was *no difference* at the population level.  This shows how group distributions can vary just from sample to sample.  

__Try it out__:  

  1. Pick a sample size and run several simulations by repeatedly clicking the button.  
  2. Repeat for a sample size of 10
  3. Repear for a sample size of 70
  
__PONDER__:  What do you notice about the impact of sample size on the sample-to-sample variability?  

<iframe src="https://byuistats.github.io/Null_Hypothesis_Simulation_App/" width="700" height="500" style="border:none;"></iframe>


Statistical hypothesis testing is about calculating the **probability** of observing what we actually observed **IF the null hypothesis were true**.  If that probability is very small, we can confidently reject the null hypothesis in favor of the alternative.  

Next, we will look at the process of calculating that probability.  


# Test Statistic

To calculate the probability of observing what we observed if there really was no relationship, we first calculate a test statistic.  

The exact formula for a test statistic depends on what type of analysis we are performing.  But regardless of the type of analysis, test statistics follow a general patter.  

A **test statistic** can be though of as a signal-to-noise ratio, where the signal is what we observed in our sample and the noise is the variability we would expect if the null hypothesis is true.  

$$\text{Test Statistics}=\frac{\text{signal}}{\text{noise}}$$
Think about this as a fraction.  

<div class="QuestionsHeading">Answer the following questions:</div>
<div class="Questions">
1. What would make $\frac{signal}{noise}$ big?  
 
<details>
<summary>Show/Hide Solution</summary>
  -  If the noise was very small
  -  If the signal was very large
</details>

2. What would make $\frac{signal}{noise}$ small?  
 
<details>
<summary>Show/Hide Solution</summary>
  -  If the noise was very large
  -  If the signal was very small
</details>

</div>

<br>

The specific formulas for test statistics vary depending on the data types you are testing, and it is something R will calculate for us.  As we get into specific analyses, we will look at a few of those formulas.  For now, consider a test statistic as a signal-to-noise ratio.  The larger it is, the stronger the evidence against the null hypothesis.  

But a test statistic is just a number and difficult to interpret in isolation.  The calculation of the test statistics is an *intermediate step* to calculating a probability.  

# Probability  

Every test statistic has a probability distribution associated with it.  The shape of that distribution depends on context, but the general process is:  

  1. Calculate the test statistic (ratio of our observation to the expected variability under $H_0$)  
  2. Use the probability distribution of the test statistic to calculate the probability of observing what we observed **if the null hypothesis were true**  


__DEFINITION__:  The probability of observing what we observed assuming the null hypothesis is true is called the **p-value**.  

A *small* p-value means that what we actually observed in our sample is unlikely to have happened just by chance (because of sample-to-sample variation).  

A *large* p-value means that our observation is likely to have occurred if the null hypothesis were true.  Our observations are consistent with sample-to-sample variation.  

In the next lesson we will talk more about decision rules for deciding when a p-value is *small enough* to reject $H_0$.  


